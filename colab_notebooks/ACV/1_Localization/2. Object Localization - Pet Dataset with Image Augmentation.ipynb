{"cells":[{"cell_type":"markdown","metadata":{"id":"hKxFOKUUo_0e"},"source":["#### Downlad the dataset"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"t3sRwJ_mo49J"},"outputs":[],"source":["#Download both images and annotations\n","!wget -q http://www.robots.ox.ac.uk/~vgg/data/pets/data/images.tar.gz\n","!wget -q http://www.robots.ox.ac.uk/~vgg/data/pets/data/annotations.tar.gz"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"0aikHskRpWE8"},"outputs":[],"source":["#Check current directory to make sure data is downloaded\n","!ls -l"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"jXSZi1law-BX"},"outputs":[],"source":["#unzip the tar files downloaded abve\n","!tar xf images.tar.gz\n","!tar xf annotations.tar.gz"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"KvrVCc0bxSvi"},"outputs":[],"source":["#Explore directories\n","!ls -l "]},{"cell_type":"code","execution_count":null,"metadata":{"id":"3pRBcHsRBOMq"},"outputs":[],"source":["#Check the xml annotations\n","!ls -l annotations/xmls"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"nUfVehWP0WLj"},"outputs":[],"source":["#Install tidy to review xml files\n","!sudo apt-get install tidy --quiet"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"tXWETTacxV4h"},"outputs":[],"source":["#Check one of the xml file to understand annotations\n","!tidy -xml -i annotations/xmls/wheaten_terrier_170.xml"]},{"cell_type":"markdown","metadata":{"id":"rDL5UxUs0nUu"},"source":["#### Convert XML to CSV"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"AZuckkwA1gHb"},"outputs":[],"source":["#Move all xml files to images folder, this is needed for python script used next\n","!mv annotations/xmls/* images/"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"L5b5pJF20r3k"},"outputs":[],"source":["#Mount Google drive (change code for local machine). We need to copy generate_dataset.py script to current directory\n","from google.colab import drive\n","drive.mount('/gdrive')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"QixCJqOk48ai"},"outputs":[],"source":["#Copy generate_dataset.py file to current directory\n","!cp \"/gdrive/My Drive/ACV/Localization/generate_dataset.py\" ."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"B8pqOIYVE8ty"},"outputs":[],"source":["!ls -l"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"AZqrnN7t1nCv"},"outputs":[],"source":["#Build csv file for both training and test dataset\n","!python generate_dataset.py"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ZirB08cx2SBr"},"outputs":[],"source":["!ls -l"]},{"cell_type":"markdown","metadata":{"id":"KIN4CgX185lH"},"source":["#### Visualize Data"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"5JvG_JZf88KP"},"outputs":[],"source":["from matplotlib import pyplot as plt\n","import cv2\n","import numpy as np\n","import pandas as pd"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"98RE4JSU2bdF"},"outputs":[],"source":["#Read csv file as pandas dataframe, csv file has no header\n","train_df = pd.read_csv('train.csv', header=None, \n","                       names=['File', 'Height','Width','xmin',\n","                              'ymin','xmax', 'ymax','Class','Label'])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"y-U19sPMCQeV"},"outputs":[],"source":["print(train_df.shape)\n","train_df.head()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"rBQRF_RC4Pzc"},"outputs":[],"source":["#Create a dictionary to hold label and corresponding class name\n","num_classes = train_df['Label'].unique()\n","label_class_dict = dict(zip(train_df['Label'], train_df['Class']))\n","#label_class_dict"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"cdex_ymSFhc4"},"outputs":[],"source":["num_classes"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"-56OxVKeGbzo"},"outputs":[],"source":["label_class_dict"]},{"cell_type":"markdown","metadata":{"id":"wTi8vgryCqh4"},"source":["Show images with bounding box"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"J-p3ne1E95Ru"},"outputs":[],"source":["#Pickup a random image number\n","img_num = np.random.randint(0, train_df.shape[0])\n","\n","#Read the image and draw a rectangle as per bounding box information\n","img = cv2.imread(train_df.loc[img_num,'File'])\n","cv2.rectangle(img, \n","             (train_df.loc[img_num, 'xmin'],train_df.loc[img_num, 'ymin']),\n","             (train_df.loc[img_num, 'xmax'],train_df.loc[img_num, 'ymax']), \n","             (0,255,0),\n","             2)\n","#Convert BGR format (used by opencv to RGB format used by matplotlib)\n","img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n","\n","#Draw image using matplotlib\n","plt.suptitle(train_df.loc[img_num, 'Class'])\n","plt.imshow(img)\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"NOnn8CixMEcw"},"outputs":[],"source":["#Read the validation csv file\n","test_df = pd.read_csv('validation.csv', header=None, \n","                       names=['File', 'Height','Width','xmin',\n","                              'ymin','xmax', 'ymax','Class','Label'])"]},{"cell_type":"markdown","metadata":{"id":"usGCdgWH5ibM"},"source":["#### Define Augmentations"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"zwd8GeOB5lIX"},"outputs":[],"source":["#Install imgaug\n","!pip install imgaug --quiet"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"VbT4mjP45s4Q"},"outputs":[],"source":["import imgaug as ia\n","from imgaug import augmenters as iaa"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"R8RGtJJKEmPK"},"outputs":[],"source":["img_size = 224\n","img_depth = 3"]},{"cell_type":"markdown","metadata":{"id":"Hb3WgeyR5zCp"},"source":["Training Augmentation Sequence"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"UuzM3Wkn5uu6"},"outputs":[],"source":["# Sometimes(0.5, ...) applies the given augmenter in 50% of all cases,\n","#sometimes = lambda aug: iaa.Sometimes(0.5, aug)\n","\n","train_seq = iaa.Sequential([    \n","    #horizontal flips 50% of the time\n","    iaa.Fliplr(0.5),\n","    #Resize all images to a specific size    \n","    iaa.Resize({\"height\": img_size, \"width\": img_size}),\n","    # Make some images brighter and some darker.\n","    # In 20% of all cases, we sample the multiplier once per channel,\n","    # which can end up changing the color of the images.\n","    # change brightness, DOES NOT AFFECT BBs\n","    iaa.Multiply((1.0, 1.5), per_channel=0.2),\n","    # translate by 40/60px on x/y axis\n","    # Rotate between 25 and -25 degrees\n","    # THIS AFFECTs BBs\n","    iaa.Sometimes(0.5, [iaa.Affine(\n","        translate_percent={\"x\": (-0.1, 0.1), \"y\": (-0.1, 0.1)},\n","        rotate=(-25, 25),\n","    )])\n","])"]},{"cell_type":"markdown","metadata":{"id":"8zXPD7sM5_G8"},"source":["Test Augmentation Sequence"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"62uUbwxu6JbP"},"outputs":[],"source":["test_seq = iaa.Sequential([    \n","    #Resize all images to a specific size    \n","    iaa.Resize({\"height\": img_size, \"width\": img_size})\n","])"]},{"cell_type":"markdown","metadata":{"id":"MEQidvGo6Ulh"},"source":["Function to apply augmentation sequence on images"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"zLxOtWni6X8G"},"outputs":[],"source":["#Augmentation function to apply on a batch\n","def apply_aug(images, bboxes, aug_seq):\n","    \n","    #Number of images to process\n","    img_count = len(images)\n","    \n","    #Make sequence deterministic\n","    seq_det = aug_seq.to_deterministic()\n","    \n","    #Initialize boxes for all images\n","    boxes = []\n","    \n","    for i in range(img_count):\n","        \n","        b_box = ia.BoundingBox(x1 = bboxes[i][0],\n","                               y1 = bboxes[i][1],\n","                               x2 = bboxes[i][2],\n","                               y2 = bboxes[i][3])\n","        \n","        boxes.append(ia.BoundingBoxesOnImage([b_box], shape=images[i].shape))\n","    \n","    #Perform image and BBs augmentation\n","    image_aug = seq_det.augment_images(images)\n","    bbs_aug = seq_det.augment_bounding_boxes(boxes)\n","    \n","    b_images = np.zeros((img_count,img_size, img_size,img_depth))\n","    b_bboxes = np.zeros((img_count, 4))\n","    \n","    for i in range(img_count):\n","        b_images[i] = image_aug[i]\n","        box_new = bbs_aug[i].bounding_boxes[0]\n","        b_bboxes[i] = [box_new.x1,\n","                       box_new.y1, \n","                       box_new.x2 - box_new.x1,\n","                       box_new.y2- box_new.y1]\n","    return b_images, b_bboxes"]},{"cell_type":"markdown","metadata":{"id":"ONbePE8pDUap"},"source":["#### Build a Batch Generator"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"iJHj-NNvEhpa"},"outputs":[],"source":["import tensorflow as tf"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"gG9qxvqfDXgJ"},"outputs":[],"source":["def batch_generator(df, batch_size=32, train_mode=True):\n","\n","    while True:\n","\n","        #Create indexes\n","        image_nums = np.random.randint(0,df.shape[0], size=batch_size)\n","\n","        #Create empty arrays\n","        #1. To hold image input\n","        batch_images = np.zeros(shape=(batch_size, img_size, img_size, 3))\n","        \n","        #Classification Labels \n","        batch_labels = np.zeros(shape=(batch_size, len(num_classes)))\n","        \n","        #Regression labels - 4 numbers per example image\n","        batch_bboxes = np.zeros(shape=(batch_size, 4))\n","        \n","        #List to hold all images which will be augmented\n","        all_images = []\n","\n","        for i in range(batch_size):\n","\n","            #Read image and resize\n","            img = tf.keras.preprocessing.image.load_img(df.loc[image_nums[i], 'File'])\n","            \n","            #Conver to numpy array - also set it to unsigned int8 data type as required by imgaug\n","            img_array = tf.keras.preprocessing.image.img_to_array(img).astype('uint8')\n","\n","            #Update batch\n","            all_images.append(img_array)\n","\n","            #Read image classification label & convert to one hot vector\n","            cl_label = df.loc[image_nums[i], 'Label']\n","            cl_label = tf.keras.utils.to_categorical(cl_label, num_classes=len(num_classes))\n","            batch_labels[i] = cl_label\n","\n","            #Read and resize bounding box co-ordinates\n","            img_width = df.loc[image_nums[i], 'Width']\n","            img_height = df.loc[image_nums[i], 'Height']\n","            \n","            xmin = df.loc[image_nums[i], 'xmin']\n","            xmax = df.loc[image_nums[i], 'xmax']\n","\n","            ymin = df.loc[image_nums[i], 'ymin']\n","            ymax = df.loc[image_nums[i], 'ymax']\n","\n","            #We will ask model to predict xmin, ymin, width and height of bounding box\n","            batch_bboxes[i] = [xmin, ymin, xmax, ymax]\n","\n","        #Apply augmentation\n","        if(train_mode):\n","            batch_images, batch_bboxes = apply_aug(all_images, batch_bboxes, train_seq)\n","        else:\n","            batch_images, batch_bboxes = apply_aug(all_images, batch_bboxes, test_seq)\n","\n","        #Normalize batch images as per Pre-trained model to be used\n","        batch_images = tf.keras.applications.resnet50.preprocess_input(batch_images)\n","        \n","        #Make bounding boxes (x, y, w, h) as numbers between 0 and 1 - this seems to work better\n","        batch_bboxes = batch_bboxes/img_size\n","\n","        #Return batch - use yield function to make it a python generator\n","        yield batch_images, [batch_labels, batch_bboxes]"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"oQcwOhGSjejh"},"outputs":[],"source":["gen = batch_generator(train_df, batch_size=2)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"hAnAIPDHjl4s"},"outputs":[],"source":["X, y = next(gen)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"BtNSq_WKj9WP"},"outputs":[],"source":["X.shape"]},{"cell_type":"markdown","metadata":{"id":"sFGPcGaMJt9-"},"source":["#### Build the Model"]},{"cell_type":"markdown","metadata":{"id":"MVXicG2xKBoq"},"source":["Load Pre-Trained Model"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"oBPc2TXuJn5m"},"outputs":[],"source":["tf.keras.backend.clear_session()\n","model = tf.keras.applications.resnet50.ResNet50(include_top=False, #Do not include FC layer at the end\n","                                          input_shape=(img_size,img_size, 3),\n","                                          weights='imagenet')"]},{"cell_type":"markdown","metadata":{"id":"Z30I35deKR2_"},"source":["Freeze all layers of Pre-trained model"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"-9U8jGq2535f"},"outputs":[],"source":["model.summary()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"_G00NdDiMLkx"},"outputs":[],"source":["len(model.layers)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Nsafx9zlKEzA"},"outputs":[],"source":["for layer in model.layers:\n","    layer.trainable = False"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"pAFqZoMQx1DP"},"outputs":[],"source":["model.summary()"]},{"cell_type":"markdown","metadata":{"id":"ochVcQl_Knjg"},"source":["Add layers"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"IrdSJfSFKXIH"},"outputs":[],"source":["#get Output layer of Pre-trained model\n","x1 = model.output\n","\n","#Add Dropout\n","x2 = tf.keras.layers.Dropout(0.5)(x1)\n","\n","#Add a convolution layer\n","x3 = tf.keras.layers.Conv2D(50, (1,1), activation='relu')(x2)\n","\n","#Flatten the output to feed to Dense layer\n","x4 = tf.keras.layers.Flatten()(x3)\n","\n","#Batch Norm\n","x5 = tf.keras.layers.BatchNormalization()(x4)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"1qCE8F1_Virj"},"outputs":[],"source":["x1"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"AcOpQdBLVkHN"},"outputs":[],"source":["x2"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"YpG03kBdVqXH"},"outputs":[],"source":["x3"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"p_krHjbTKEDw"},"outputs":[],"source":["x4"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"W-sthIqDVt7P"},"outputs":[],"source":["x5"]},{"cell_type":"markdown","metadata":{"id":"dSsesgHCKuq0"},"source":["Build layer for Label output"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"KUyBwuxlKt67"},"outputs":[],"source":["#Classification\n","label_output = tf.keras.layers.Dense(len(num_classes), activation='softmax', name='class_op')(x5)"]},{"cell_type":"markdown","metadata":{"id":"smOcT5VLK6BA"},"source":["Build layer for bounding box output"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Ujk5IXzIK9O1"},"outputs":[],"source":["#Regression\n","bbox_output = tf.keras.layers.Dense(4 , activation='sigmoid', name='reg_op')(x5)"]},{"cell_type":"markdown","metadata":{"id":"dSvjuIa2LlOY"},"source":["Finalize the model"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"n3frSPd3Lj7i"},"outputs":[],"source":["#Non Sequential model as it has two different outputs\n","final_model = tf.keras.models.Model(inputs=model.input, #Pre-trained model input as input layer\n","                                    outputs=[label_output,bbox_output]) #Output layer added"]},{"cell_type":"markdown","metadata":{"id":"HJBxJI-jjYXu"},"source":["Define IoU Metrics"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"NnWhJ5bTjaSj"},"outputs":[],"source":["def calculate_iou(y_true, y_pred):\n","    \n","    \n","    \"\"\"\n","    Input:\n","    Keras provides the input as numpy arrays with shape (batch_size, num_columns).\n","    \n","    Arguments:\n","    y_true -- first box, numpy array with format [x, y, width, height, conf_score]\n","    y_pred -- second box, numpy array with format [x, y, width, height, conf_score]\n","    x any y are the coordinates of the top left corner of each box.\n","    \n","    Output: IoU of type float32. (This is a ratio. Max is 1. Min is 0.)\n","    \n","    \"\"\"\n","\n","    \n","    results = []\n","    \n","    for i in range(0,y_true.shape[0]):\n","    \n","        # set the types so we are sure what type we are using\n","        y_true = np.array(y_true, dtype=np.float32)\n","        y_pred = np.array(y_pred, dtype=np.float32)\n","\n","        #print(y_true.shape)\n","        #print(y_pred.shape)\n","        # boxTrue\n","        x_boxTrue_tleft = y_true[i,0]  # numpy index selection\n","        y_boxTrue_tleft = y_true[i,1]\n","        boxTrue_width = y_true[i,2]\n","        boxTrue_height = y_true[i,3]\n","        area_boxTrue = (boxTrue_width * boxTrue_height)\n","\n","        # boxPred\n","        x_boxPred_tleft = y_pred[i,0]\n","        y_boxPred_tleft = y_pred[i,1]\n","        boxPred_width = y_pred[i,2]\n","        boxPred_height = y_pred[i,3]\n","        area_boxPred = (boxPred_width * boxPred_height)\n","\n","        # calculate the bottom right coordinates for boxTrue and boxPred\n","\n","        # boxTrue\n","        x_boxTrue_br = x_boxTrue_tleft + boxTrue_width\n","        y_boxTrue_br = y_boxTrue_tleft + boxTrue_height # Version 2 revision\n","\n","        # boxPred\n","        x_boxPred_br = x_boxPred_tleft + boxPred_width\n","        y_boxPred_br = y_boxPred_tleft + boxPred_height # Version 2 revision\n","\n","\n","        # calculate the top left and bottom right coordinates for the intersection box, boxInt\n","\n","        # boxInt - top left coords\n","        x_boxInt_tleft = np.max([x_boxTrue_tleft,x_boxPred_tleft])\n","        y_boxInt_tleft = np.max([y_boxTrue_tleft,y_boxPred_tleft]) # Version 2 revision\n","\n","        # boxInt - bottom right coords\n","        x_boxInt_br = np.min([x_boxTrue_br,x_boxPred_br])\n","        y_boxInt_br = np.min([y_boxTrue_br,y_boxPred_br]) \n","\n","        # Calculate the area of boxInt, i.e. the area of the intersection \n","        # between boxTrue and boxPred.\n","        # The np.max() function forces the intersection area to 0 if the boxes don't overlap.\n","        \n","        \n","        # Version 2 revision\n","        area_of_intersection = \\\n","        np.max([0,(x_boxInt_br - x_boxInt_tleft)]) * np.max([0,(y_boxInt_br - y_boxInt_tleft)])\n","\n","        iou = area_of_intersection / ((area_boxTrue + area_boxPred) - area_of_intersection)\n","\n","\n","        # This must match the type used in py_func\n","        iou = np.array(iou, dtype=np.float32)\n","        \n","        # append the result to a list at the end of each loop\n","        results.append(iou)\n","    \n","    # return the mean IoU score for the batch\n","    return np.mean(results)\n","\n","\n","\n","def IoU(y_true, y_pred):\n","    \n","    # Note: the type float32 is very important. It must be the same type as the output from\n","    # the python function above or you too may spend many late night hours \n","    # trying to debug and almost give up.\n","    \n","    iou = tf.py_function(calculate_iou, [y_true, y_pred], tf.float32)\n","\n","    return iou"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"5EtT4eO7NzJF"},"outputs":[],"source":["model_checkpoint = tf.keras.callbacks.ModelCheckpoint(\"pets.h5\", save_best_only=True, verbose=1)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"qfVR7QqYLyNz"},"outputs":[],"source":["final_model.compile(optimizer='adam', \n","                    #loss=['categorical_crossentropy', 'mae'],\n","                    loss={'reg_op':'mse', 'class_op':'categorical_crossentropy'},\n","                    loss_weights={'reg_op':1, 'class_op':1},\n","                    metrics={'reg_op':[IoU], 'class_op':['accuracy']})"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"z1xWiz4z7w26"},"outputs":[],"source":["final_model.summary()"]},{"cell_type":"markdown","metadata":{"id":"-RQg_TeWL8CC"},"source":["Train the model"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"aLOR7EApL6cl"},"outputs":[],"source":["#Create train and test generator\n","batchsize = 64\n","train_generator = batch_generator(train_df, batch_size=batchsize, train_mode=True) #batchsize can be changed\n","test_generator = batch_generator(test_df, batch_size=batchsize, train_mode=False)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"lIXCKbrLMR47"},"outputs":[],"source":["final_model.fit(train_generator,\n","                epochs=3,\n","                steps_per_epoch= train_df.shape[0]//batchsize,\n","                validation_data=test_generator,\n","                validation_steps = test_df.shape[0]//batchsize, \n","                callbacks=[model_checkpoint])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"v-dGMpw5zUsS"},"outputs":[],"source":["final_model.compile(optimizer='adam', \n","                    loss={'reg_op':'mse', 'class_op':'categorical_crossentropy'},\n","                    loss_weights={'reg_op':20, 'class_op':1},\n","                    metrics={'reg_op':[IoU], 'class_op':['accuracy']})"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"jevCL37Szde3"},"outputs":[],"source":["final_model.fit(train_generator,\n","                epochs=50,\n","                initial_epoch=3,\n","                steps_per_epoch= train_df.shape[0]//batchsize,\n","                validation_data=test_generator,\n","                validation_steps = test_df.shape[0]//batchsize, \n","                callbacks=[model_checkpoint])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"GN4bsbSGUtOI"},"outputs":[],"source":["!ls -l"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"QwxRXhRaVlEZ"},"outputs":[],"source":["final_model = tf.keras.models.load_model('pets.h5', custom_objects={'IoU':IoU})"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"5msq1-6tX3lJ"},"outputs":[],"source":["final_model.save('/gdrive/My Drive/pets.h5')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"qXd9lFdZejdH"},"outputs":[],"source":["final_model"]},{"cell_type":"markdown","metadata":{"id":"RT_TJaPWX2PK"},"source":["#### Model Prediction"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"WyrMXl9EdiSt"},"outputs":[],"source":["def predict_and_draw(image_num, df):\n","\n","    #Load image\n","    img = tf.keras.preprocessing.image.load_img(df.loc[image_num, 'File'])\n","    w, h = img.size\n","\n","    #Read actual label and bounding box\n","    act_class = df.loc[image_num, 'Class']\n","    xmin, ymin, xmax, ymax = df.loc[image_num, ['xmin', 'ymin', 'xmax', 'ymax']]\n","    \n","    #Prepare input for model\n","    #1. Resize image\n","    img_resized = img.resize((img_size, img_size)) \n","    #2. Conver to array and make it a batch of 1\n","    input_array = tf.keras.preprocessing.image.img_to_array(img_resized)\n","    input_array = np.expand_dims(input_array, axis=0)\n","    #3. Normalize image data\n","    input_array = tf.keras.applications.resnet50.preprocess_input(input_array)\n","\n","    #Prediction\n","    pred = final_model.predict(input_array)\n","    #Get classification and regression predictions\n","    label_pred, bbox_pred = pred[0][0], pred[1][0]\n","    print(label_pred)\n","    print(bbox_pred)\n","    #Get Label with highest probability\n","    pred_class = label_class_dict[np.argmax(label_pred)]\n","\n","    print('Real Label :', act_class, '\\nPredicted Label: ', pred_class)\n","    \n","    #Draw bounding boxes - Actual (Red) and Predicted(Green)\n","    img = cv2.imread(df.loc[image_num, 'File'])\n","    #Draw actual bounding box\n","    img = cv2.rectangle(img, (xmin, ymin), \n","                        (xmax, ymax), (0,0,255), 2)\n","    #Draw predicted bounding box\n","    img = cv2.rectangle(img, (int(bbox_pred[0]*w), int(bbox_pred[1]*h)), \n","                        (int((bbox_pred[0]+bbox_pred[2])*w), int((bbox_pred[1]+bbox_pred[3])*h)), (0,255,0), 2)\n","\n","    #Display the picture\n","    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n","    plt.imshow(img)\n","    plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"DH0bH4YiYZ4b"},"outputs":[],"source":["#Predict on Test Dataset\n","image_num = np.random.randint(0, test_df.shape[0])\n","predict_and_draw(437, test_df)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"_eZDd_TSerAk"},"outputs":[],"source":["image_num"]}],"metadata":{"accelerator":"GPU","colab":{"collapsed_sections":[],"name":"2. Object Localization - Pet Dataset with Image Augmentation.ipynb","private_outputs":true,"provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"}},"nbformat":4,"nbformat_minor":0}
