{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "X_cdgs6Gtnsc"
   },
   "source": [
    "#### Load TensorFlow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "5b_EywEw4MMe"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.9.2'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "tf.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "21W7saMGt1_F"
   },
   "source": [
    "#### Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "2F_QcYwH4u7I"
   },
   "outputs": [],
   "source": [
    "#Load Boston Housing Dataset\n",
    "(train_x, train_y),(_,_) = tf.keras.datasets.boston_housing.load_data(test_split=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "pcDQYh3SBUNV"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  1.23247,   0.     ,   8.14   ,   0.     ,   0.538  ,   6.142  ,\n",
       "        91.7    ,   3.9769 ,   4.     , 307.     ,  21.     , 396.9    ,\n",
       "        18.72   ])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_x[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "lADXNbMKGH_g"
   },
   "outputs": [],
   "source": [
    "train_x = train_x.astype('float32')\n",
    "train_y = train_y.astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "TKDsS4vKGl3E"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(506, 13)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "FXk9VbBz_Mbh"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(506,)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AiN_ErR0IADp"
   },
   "source": [
    "Normalize input features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "6ZqHpTR3zk6G"
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import Normalizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "NPqcYGULzifH"
   },
   "outputs": [],
   "source": [
    "transformer = Normalizer()\n",
    "train_x = transformer.fit_transform(train_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "1RUXHjKml5Z8"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.0024119 , 0.        , 0.01592969, 0.        , 0.00105285,\n",
       "       0.01201967, 0.17945357, 0.00778265, 0.00782785, 0.6007879 ,\n",
       "       0.04109624, 0.7767189 , 0.03663436], dtype=float32)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_x[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fOIoE3qCt9Wp"
   },
   "source": [
    "#### Build Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uSMg5HDluCZG"
   },
   "source": [
    "Define Weights and Bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "1qHkc0mS_KZP"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metal device set to: Apple M1 Max\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-21 23:42:01.387752: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:305] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2024-02-21 23:42:01.388230: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:271] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n"
     ]
    }
   ],
   "source": [
    "#We are initializing weights and Bias with Zero\n",
    "w = tf.random.normal(shape=(13,1))\n",
    "b = tf.zeros(shape=(1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MP8U92hduNeV"
   },
   "source": [
    "Define a function to calculate prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "ARk9SVAb_jBA"
   },
   "outputs": [],
   "source": [
    "def prediction(x, w, b):\n",
    "    \n",
    "    xw_matmul = tf.matmul(x, w)\n",
    "    y = tf.add(xw_matmul, b)\n",
    "    \n",
    "    return y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0QKcoDtbuhDl"
   },
   "source": [
    "Function to calculate Loss (Mean Squared Error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "zEkRNWEa_q45"
   },
   "outputs": [],
   "source": [
    "def loss(y_actual, y_predicted):\n",
    "    \n",
    "    diff = y_actual - y_predicted\n",
    "    sqr = tf.square(diff)\n",
    "    avg = tf.reduce_mean(sqr)\n",
    "    \n",
    "    return avg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2U2j7okPul9V"
   },
   "source": [
    "Function to train the Model\n",
    "\n",
    "1.   Record all the mathematical steps to calculate Loss\n",
    "2.   Calculate Gradients of Loss w.r.t weights and bias\n",
    "3.   Update Weights and Bias based on gradients and learning rate\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "r_Zu3u8IARZu"
   },
   "outputs": [],
   "source": [
    "def train(x, y_actual, w, b, learning_rate=0.01):\n",
    "    \n",
    "    #Record mathematical operations on 'tape' to calculate loss\n",
    "    with tf.GradientTape() as t:\n",
    "        \n",
    "        t.watch([w,b])\n",
    "        \n",
    "        current_prediction = prediction(x, w, b)\n",
    "        current_loss = loss(y_actual, current_prediction)\n",
    "    \n",
    "    #Calculate Gradients for Loss with respect to Weights and Bias\n",
    "    dw, db = t.gradient(current_loss,[w, b])\n",
    "    \n",
    "    #Update Weights and Bias\n",
    "    w = w - learning_rate*dw\n",
    "    b = b - learning_rate*db\n",
    "    \n",
    "    return w, b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zcXDZ6N5vNw-"
   },
   "source": [
    "#### Start Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "gOY134RfEpbq"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Loss on iteration 0 582.8071\n",
      "Current Loss on iteration 1 545.1161\n",
      "Current Loss on iteration 2 510.27744\n",
      "Current Loss on iteration 3 478.07535\n",
      "Current Loss on iteration 4 448.31027\n",
      "Current Loss on iteration 5 420.79776\n",
      "Current Loss on iteration 6 395.36734\n",
      "Current Loss on iteration 7 371.86154\n",
      "Current Loss on iteration 8 350.13452\n",
      "Current Loss on iteration 9 330.05182\n",
      "Current Loss on iteration 10 311.48895\n",
      "Current Loss on iteration 11 294.3308\n",
      "Current Loss on iteration 12 278.47125\n",
      "Current Loss on iteration 13 263.81186\n",
      "Current Loss on iteration 14 250.26186\n",
      "Current Loss on iteration 15 237.7373\n",
      "Current Loss on iteration 16 226.16058\n",
      "Current Loss on iteration 17 215.45996\n",
      "Current Loss on iteration 18 205.56909\n",
      "Current Loss on iteration 19 196.42677\n",
      "Current Loss on iteration 20 187.9763\n",
      "Current Loss on iteration 21 180.16533\n",
      "Current Loss on iteration 22 172.94548\n",
      "Current Loss on iteration 23 166.272\n",
      "Current Loss on iteration 24 160.10352\n",
      "Current Loss on iteration 25 154.40184\n",
      "Current Loss on iteration 26 149.13165\n",
      "Current Loss on iteration 27 144.26028\n",
      "Current Loss on iteration 28 139.75754\n",
      "Current Loss on iteration 29 135.59555\n",
      "Current Loss on iteration 30 131.7485\n",
      "Current Loss on iteration 31 128.19257\n",
      "Current Loss on iteration 32 124.90573\n",
      "Current Loss on iteration 33 121.86763\n",
      "Current Loss on iteration 34 119.05941\n",
      "Current Loss on iteration 35 116.463684\n",
      "Current Loss on iteration 36 114.0644\n",
      "Current Loss on iteration 37 111.84665\n",
      "Current Loss on iteration 38 109.79672\n",
      "Current Loss on iteration 39 107.90191\n",
      "Current Loss on iteration 40 106.15047\n",
      "Current Loss on iteration 41 104.531555\n",
      "Current Loss on iteration 42 103.035126\n",
      "Current Loss on iteration 43 101.651924\n",
      "Current Loss on iteration 44 100.37339\n",
      "Current Loss on iteration 45 99.19158\n",
      "Current Loss on iteration 46 98.0992\n",
      "Current Loss on iteration 47 97.089455\n",
      "Current Loss on iteration 48 96.156105\n",
      "Current Loss on iteration 49 95.293365\n",
      "Current Loss on iteration 50 94.4959\n",
      "Current Loss on iteration 51 93.75877\n",
      "Current Loss on iteration 52 93.07739\n",
      "Current Loss on iteration 53 92.44755\n",
      "Current Loss on iteration 54 91.865364\n",
      "Current Loss on iteration 55 91.32722\n",
      "Current Loss on iteration 56 90.82976\n",
      "Current Loss on iteration 57 90.36994\n",
      "Current Loss on iteration 58 89.94489\n",
      "Current Loss on iteration 59 89.55199\n",
      "Current Loss on iteration 60 89.18879\n",
      "Current Loss on iteration 61 88.85307\n",
      "Current Loss on iteration 62 88.542725\n",
      "Current Loss on iteration 63 88.255844\n",
      "Current Loss on iteration 64 87.99065\n",
      "Current Loss on iteration 65 87.74551\n",
      "Current Loss on iteration 66 87.5189\n",
      "Current Loss on iteration 67 87.30941\n",
      "Current Loss on iteration 68 87.11575\n",
      "Current Loss on iteration 69 86.93673\n",
      "Current Loss on iteration 70 86.77124\n",
      "Current Loss on iteration 71 86.61824\n",
      "Current Loss on iteration 72 86.47681\n",
      "Current Loss on iteration 73 86.346054\n",
      "Current Loss on iteration 74 86.225174\n",
      "Current Loss on iteration 75 86.11343\n",
      "Current Loss on iteration 76 86.01009\n",
      "Current Loss on iteration 77 85.91457\n",
      "Current Loss on iteration 78 85.82627\n",
      "Current Loss on iteration 79 85.74461\n",
      "Current Loss on iteration 80 85.66913\n",
      "Current Loss on iteration 81 85.59932\n",
      "Current Loss on iteration 82 85.53477\n",
      "Current Loss on iteration 83 85.4751\n",
      "Current Loss on iteration 84 85.41992\n",
      "Current Loss on iteration 85 85.36889\n",
      "Current Loss on iteration 86 85.32169\n",
      "Current Loss on iteration 87 85.27805\n",
      "Current Loss on iteration 88 85.2377\n",
      "Current Loss on iteration 89 85.20038\n",
      "Current Loss on iteration 90 85.16586\n",
      "Current Loss on iteration 91 85.133934\n",
      "Current Loss on iteration 92 85.10441\n",
      "Current Loss on iteration 93 85.07709\n",
      "Current Loss on iteration 94 85.0518\n",
      "Current Loss on iteration 95 85.028435\n",
      "Current Loss on iteration 96 85.0068\n",
      "Current Loss on iteration 97 84.986786\n",
      "Current Loss on iteration 98 84.96826\n",
      "Current Loss on iteration 99 84.951126\n"
     ]
    }
   ],
   "source": [
    "for i in range(100):\n",
    "    \n",
    "    w, b = train(train_x, train_y, w, b, learning_rate=0.01)\n",
    "    print('Current Loss on iteration', i, loss(train_y, \n",
    "                                               prediction(train_x, w, b)).numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "DDcxSozRxyer"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weights:\n",
      " [[ 1.3317236e+00]\n",
      " [-1.5965809e-01]\n",
      " [ 9.6345782e-02]\n",
      " [-3.8291898e-01]\n",
      " [ 5.3024715e-01]\n",
      " [-5.9402573e-01]\n",
      " [ 4.0946002e-03]\n",
      " [-7.6564604e-01]\n",
      " [ 6.9044702e-02]\n",
      " [ 7.9550939e+00]\n",
      " [-1.5746429e+00]\n",
      " [ 7.2633352e+00]\n",
      " [ 9.9591506e-01]]\n",
      "Bias:\n",
      " [11.824347]\n"
     ]
    }
   ],
   "source": [
    "#Check Weights and Bias\n",
    "print('Weights:\\n', w.numpy())\n",
    "print('Bias:\\n',b.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "NqGz1fuKYzxP"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Loss on iteration 0 84.935265\n",
      "Current Loss on iteration 1 84.92058\n",
      "Current Loss on iteration 2 84.90698\n",
      "Current Loss on iteration 3 84.89441\n",
      "Current Loss on iteration 4 84.88275\n",
      "Current Loss on iteration 5 84.871956\n",
      "Current Loss on iteration 6 84.86198\n",
      "Current Loss on iteration 7 84.85271\n",
      "Current Loss on iteration 8 84.844124\n",
      "Current Loss on iteration 9 84.83618\n",
      "Current Loss on iteration 10 84.82881\n",
      "Current Loss on iteration 11 84.82199\n",
      "Current Loss on iteration 12 84.81565\n",
      "Current Loss on iteration 13 84.80978\n",
      "Current Loss on iteration 14 84.80434\n",
      "Current Loss on iteration 15 84.79928\n",
      "Current Loss on iteration 16 84.79459\n",
      "Current Loss on iteration 17 84.79023\n",
      "Current Loss on iteration 18 84.78619\n",
      "Current Loss on iteration 19 84.782425\n",
      "Current Loss on iteration 20 84.77892\n",
      "Current Loss on iteration 21 84.77568\n",
      "Current Loss on iteration 22 84.77265\n",
      "Current Loss on iteration 23 84.769844\n",
      "Current Loss on iteration 24 84.76722\n",
      "Current Loss on iteration 25 84.76478\n",
      "Current Loss on iteration 26 84.762505\n",
      "Current Loss on iteration 27 84.760376\n",
      "Current Loss on iteration 28 84.75839\n",
      "Current Loss on iteration 29 84.75655\n",
      "Current Loss on iteration 30 84.754814\n",
      "Current Loss on iteration 31 84.75321\n",
      "Current Loss on iteration 32 84.75169\n",
      "Current Loss on iteration 33 84.750275\n",
      "Current Loss on iteration 34 84.74893\n",
      "Current Loss on iteration 35 84.747696\n",
      "Current Loss on iteration 36 84.74652\n",
      "Current Loss on iteration 37 84.74542\n",
      "Current Loss on iteration 38 84.744385\n",
      "Current Loss on iteration 39 84.7434\n",
      "Current Loss on iteration 40 84.74248\n",
      "Current Loss on iteration 41 84.741615\n",
      "Current Loss on iteration 42 84.74079\n",
      "Current Loss on iteration 43 84.740005\n",
      "Current Loss on iteration 44 84.73927\n",
      "Current Loss on iteration 45 84.73857\n",
      "Current Loss on iteration 46 84.7379\n",
      "Current Loss on iteration 47 84.73727\n",
      "Current Loss on iteration 48 84.736664\n",
      "Current Loss on iteration 49 84.736084\n"
     ]
    }
   ],
   "source": [
    "for i in range(50):\n",
    "    \n",
    "    w, b = train(train_x, train_y, w, b)\n",
    "    print('Current Loss on iteration', i, loss(train_y, prediction(train_x, w, b)).numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "2b. Boston Housing Prices_Normalization.ipynb",
   "private_outputs": true,
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
