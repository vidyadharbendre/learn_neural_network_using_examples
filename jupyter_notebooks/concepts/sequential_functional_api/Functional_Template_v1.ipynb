{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "484d8695-cec3-41d0-9a9a-c28d849c3596",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the TensorFlow library, commonly aliased as 'tf', for building and training neural networks.\n",
    "import tensorflow as tf\n",
    "\n",
    "# Import the NumPy library, commonly aliased as 'np', for numerical computations and array operations.\n",
    "import numpy as np\n",
    "\n",
    "# Import the Pandas library, commonly aliased as 'pd', for data manipulation and analysis.\n",
    "import pandas as pd\n",
    "\n",
    "# Import the Matplotlib library, specifically the pyplot module, for data visualization.\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2baf7efc-9438-4571-8fea-826da0d39d49",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the MNIST dataset from the TensorFlow Keras datasets module.\n",
    "from tensorflow.keras.datasets import mnist\n",
    "\n",
    "# Import the to_categorical function from the TensorFlow Keras utils module.\n",
    "# This function is used for one-hot encoding of categorical labels.\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "# Import the clear_session function from the TensorFlow Keras backend module.\n",
    "# This function is used to clear the Keras session and reset the TensorFlow graph.\n",
    "from tensorflow.keras.backend import clear_session\n",
    "\n",
    "# Import the Sequential and Model classes from the TensorFlow Keras models module.\n",
    "# These classes are used to create sequential and functional API models, respectively.\n",
    "from tensorflow.keras.models import Sequential, Model, load_model\n",
    "\n",
    "# Import various layer classes (Reshape, Dense, BatchNormalization, LeakyReLU, Input)\n",
    "# from the TensorFlow Keras layers module.\n",
    "# These classes are used to define the architecture of neural network models.\n",
    "from tensorflow.keras.layers import Reshape, Dense, BatchNormalization, LeakyReLU, Input\n",
    "\n",
    "# Import callback classes (ModelCheckpoint, EarlyStopping) from the TensorFlow Keras callbacks module.\n",
    "# These classes are used to define callbacks for monitoring and controlling the training process.\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b91d1831-f6d0-488d-b94f-3b0ad651c439",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download the MNIST dataset using the load_data() function from the mnist module.\n",
    "# The dataset consists of handwritten digits (0 to 9) and is commonly used for image classification tasks.\n",
    "# It returns training and testing data as tuples (X_train, y_train) and (X_test, y_test) respectively,\n",
    "# where X_train and X_test are the input images and y_train and y_test are the corresponding labels.\n",
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e6ad17d6-e14f-4f61-8bb0-4a6f9a7b78bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reshape the training and testing input images (X_train and X_test) from 2D arrays (28x28 pixels)\n",
    "# to 1D arrays (784 pixels) using the reshape() method. This flattens each image into a single vector.\n",
    "# The argument (-1, 28*28) specifies the new shape, where -1 indicates that the number of rows (samples)\n",
    "# is inferred based on the size of the original array, and 28*28 is the total number of pixels in each image.\n",
    "X_train = X_train.reshape(-1, 28*28).astype(\"float32\") / 255.0\n",
    "X_test = X_test.reshape(-1, 28*28).astype(\"float32\") / 255.0\n",
    "\n",
    "# Convert pixel values of training and testing input images to floating-point numbers and normalize them\n",
    "# by dividing by 255.0. This scales the pixel values to the range [0, 1], which helps improve the convergence\n",
    "# and stability of the training process when using neural networks.\n",
    "# The astype(\"float32\") method converts the pixel values to 32-bit floating-point numbers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "88ccb6da-40c3-4c4e-9840-1a7bdd50d497",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((60000, 784), (60000,), (10000, 784), (10000,))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, y_train.shape, X_test.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fa98de6f-a663-442d-8fe9-43d439bb7cfc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Data - Input Shape: (60000, 784)\n",
      "Training Data - Label Shape: (60000,)\n",
      "Testing Data - Input Shape: (10000, 784)\n",
      "Testing Data - Label Shape: (10000,)\n"
     ]
    }
   ],
   "source": [
    "# Print the shapes of the training and testing datasets to understand their dimensions.\n",
    "# X_train.shape: Shape of the training input data (X_train).\n",
    "# y_train.shape: Shape of the training labels (y_train).\n",
    "# X_test.shape: Shape of the testing input data (X_test).\n",
    "# y_test.shape: Shape of the testing labels (y_test).\n",
    "print(\"Training Data - Input Shape:\", X_train.shape)\n",
    "print(\"Training Data - Label Shape:\", y_train.shape)\n",
    "print(\"Testing Data - Input Shape:\", X_test.shape)\n",
    "print(\"Testing Data - Label Shape:\", y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "5027de04-078a-42ab-a9a4-a5b4d1706f26",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Reshape the image data back to its original shape (28x28)\n",
    "image = X_train[3707].reshape(28, 28)\n",
    "\n",
    "# Display the image using plt.imshow()\n",
    "plt.imshow(image, cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "04837982-111a-45f2-a7ee-4738946cd699",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label for example at index 3707 in the test set: [0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "# Obtain the label for a specific example in the test set.\n",
    "# Here, y_train[3707] retrieves the label corresponding to the example at index 3707 in the test set.\n",
    "example_label = y_train[3707]\n",
    "\n",
    "# Print the label of the example.\n",
    "print(\"Label for example at index 3707 in the test set:\", example_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "555ffd1e-0971-4c0b-a74e-6ec0e2fd6522",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Reshape the image data back to its original shape (28x28)\n",
    "image = X_test[3707].reshape(28, 28)\n",
    "\n",
    "# Display the image using plt.imshow()\n",
    "plt.imshow(image, cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1baec0ae-d1e3-4f00-b0c6-203b978ed078",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label for example at index 3707 in the test set: 8\n"
     ]
    }
   ],
   "source": [
    "# Obtain the label for a specific example in the test set.\n",
    "# Here, y_test[3707] retrieves the label corresponding to the example at index 3707 in the test set.\n",
    "example_label = y_test[3707]\n",
    "\n",
    "# Print the label of the example.\n",
    "print(\"Label for example at index 3707 in the test set:\", example_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b8ef7a62-7f53-460b-a5d0-35f864054e04",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the training and testing labels (y_train and y_test) to one-hot encoded format using the to_categorical function\n",
    "# from the TensorFlow Keras utils module. One-hot encoding converts categorical integer labels (0 to 9) into binary vectors\n",
    "# with a length equal to the number of classes (10 in this case), where a 1 is placed in the index corresponding to the class label,\n",
    "# and 0s elsewhere.\n",
    "y_train = tf.keras.utils.to_categorical(y_train, num_classes=10)\n",
    "y_test = tf.keras.utils.to_categorical(y_test, num_classes=10)\n",
    "\n",
    "# The num_classes parameter specifies the total number of classes for one-hot encoding, which is set to 10 for the MNIST dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bcf19560-8792-44e4-9abc-36d6563a9d55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "One-hot encoded label for example at index 3707 in the test set: [0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n"
     ]
    }
   ],
   "source": [
    "# Obtain the one-hot encoded label for a specific example in the test set.\n",
    "# Here, y_test[3707] retrieves the one-hot encoded label corresponding to the example at index 3707 in the test set.\n",
    "example_label_one_hot = y_test[3707]\n",
    "\n",
    "# Print the one-hot encoded label of the example.\n",
    "print(\"One-hot encoded label for example at index 3707 in the test set:\", example_label_one_hot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a3b04720-77ad-46b1-ba2a-a14764894f36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metal device set to: Apple M1 Max\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-21 06:01:30.030798: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:305] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2024-03-21 06:01:30.030947: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:271] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n"
     ]
    }
   ],
   "source": [
    "### version -1 ###\n",
    "# Clear any existing TensorFlow graph/session.\n",
    "clear_session()\n",
    "\n",
    "# Import necessary libraries and functions from TensorFlow.\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Dense\n",
    "\n",
    "# Define the input layer with a shape of (784,), representing flattened 28x28 images.\n",
    "inputs = Input(shape=(784))\n",
    "\n",
    "# Define the architecture of the neural network using fully connected (Dense) layers.\n",
    "# Reshape data from 2D to 1D -> 28x28 to 784\n",
    "# Add the first hidden layer with 512 neurons and ReLU activation function.\n",
    "first_hidden_layer = Dense(512, activation=\"relu\", name=\"first_layer\")(inputs)\n",
    "\n",
    "# Add the second hidden layer with 256 neurons and ReLU activation function.\n",
    "second_hidden_layer = Dense(256, activation=\"relu\", name=\"second_layer\")(first_hidden_layer)\n",
    "\n",
    "# Add the third hidden layer with 128 neurons and ReLU activation function.\n",
    "third_hidden_layer = Dense(128, activation=\"relu\", name=\"third_layer\")(second_hidden_layer)\n",
    "\n",
    "# Add the fourth hidden layer with 64 neurons and ReLU activation function.\n",
    "fourth_hidden_layer = Dense(64, activation=\"relu\", name=\"fourth_layer\")(third_hidden_layer)\n",
    "\n",
    "# Add the output layer with 10 neurons (for 10 classes) and softmax activation function.\n",
    "outputs = Dense(10, activation='softmax')(fourth_hidden_layer)\n",
    "\n",
    "# Define the model with input and output layers.\n",
    "model = Model(inputs=inputs, outputs=outputs)\n",
    "\n",
    "# Compile the model with stochastic gradient descent (SGD) optimizer, categorical crossentropy loss,\n",
    "# and accuracy metric for evaluation during training.\n",
    "model.compile(optimizer='sgd', loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e0d3967a-56e4-4277-9c2d-6a01a067e74b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 784)]             0         \n",
      "                                                                 \n",
      " first_layer (Dense)         (None, 512)               401920    \n",
      "                                                                 \n",
      " second_layer (Dense)        (None, 256)               131328    \n",
      "                                                                 \n",
      " third_layer (Dense)         (None, 128)               32896     \n",
      "                                                                 \n",
      " fourth_layer (Dense)        (None, 64)                8256      \n",
      "                                                                 \n",
      " dense (Dense)               (None, 10)                650       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 575,050\n",
      "Trainable params: 575,050\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Review the summary of the model, which provides a concise representation\n",
    "# of the model architecture, including the type and shape of each layer,\n",
    "# as well as the number of parameters in each layer.\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "128941e0-81df-49a1-b020-1771924ed4b3",
   "metadata": {},
   "source": [
    "In the context of machine learning, both model checkpoints and callbacks are tools used to improve the training process of neural networks, particularly in deep learning frameworks like TensorFlow and PyTorch. However, they serve different purposes:\n",
    "\n",
    "Model Checkpoint:\n",
    "\n",
    "A model checkpoint is a feature used to save the model's current weights or entire state at certain intervals during training.\n",
    "The primary purpose of a model checkpoint is to save the model's progress periodically so that it can be restored or used later for inference or further training.\n",
    "Model checkpoints are typically used to save the best-performing model based on a specified metric, such as validation accuracy or loss. This ensures that you retain the best version of the model throughout the training process.\n",
    "Checkpoints are especially useful for long training processes where interruptions or failures may occur, allowing you to resume training from the last saved checkpoint rather than starting from scratch.\n",
    "Callback:\n",
    "\n",
    "A callback is a function or set of functions that are executed at specific points during the training process, such as at the beginning or end of an epoch or after a batch of data is processed.\n",
    "Callbacks are more versatile and can perform various tasks during training, such as logging training metrics, adjusting learning rates dynamically, implementing early stopping, or saving model checkpoints.\n",
    "While model checkpoints are a specific type of callback used for saving model weights, callbacks can perform a wide range of additional functions to customize the training process according to your specific needs.\n",
    "Callbacks can be defined by the user or provided by the deep learning framework as pre-defined functions. Users can also create custom callbacks to implement specific behaviors not covered by built-in callbacks.\n",
    "In summary, a model checkpoint is a type of callback used specifically for saving model weights or state during training, while callbacks encompass a broader range of functions that can be executed at various stages of the training process to customize and enhance the training procedure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1c15c4b0-c8f5-4c4b-8641-d763c3095da5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ModelCheckpoint callback to save the best model based on validation accuracy\n",
    "model_checkpoint = ModelCheckpoint(\n",
    "    'mnist_functional_template_v1.h5',  # File path to save the model\n",
    "    save_best_only=True,       # Save only the best model based on monitored metric\n",
    "    monitor='val_accuracy',    # Metric to monitor for determining the best model\n",
    "    mode='max',                # Mode for determining the best model ('max' or 'min')\n",
    "    verbose=1                  # Verbosity mode (0 or 1)\n",
    ")\n",
    "\n",
    "# EarlyStopping callback to stop training when the monitored metric stops improving\n",
    "early_stopping = EarlyStopping(\n",
    "    monitor='val_loss',        # Metric to monitor for early stopping\n",
    "    patience=5,                # Number of epochs with no improvement after which training will be stopped\n",
    "    verbose=1,                 # Verbosity mode (0 or 1)\n",
    "    restore_best_weights=True  # Whether to restore model weights from the epoch with the best value of the monitored quantity\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c2db5a9-573f-4053-9f4b-38aee40c4a76",
   "metadata": {},
   "source": [
    "Using both callbacks allows you to save the best model based on a monitored metric while also stopping the training process if the model's performance on a validation set stops improving, thereby preventing overfitting. This combination can help you find the best-performing model while avoiding unnecessary training epochs. It's a recommended practice for many training scenarios."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "034681c2-b161-44a9-918a-223a831c970f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "1874/1875 [============================>.] - ETA: 0s - loss: 0.1652 - accuracy: 0.9519\n",
      "Epoch 1: val_accuracy improved from -inf to 0.95300, saving model to mnist_functional_template_v1.h5\n",
      "1875/1875 [==============================] - 20s 10ms/step - loss: 0.1653 - accuracy: 0.9519 - val_loss: 0.1539 - val_accuracy: 0.9530\n",
      "Epoch 2/2\n",
      "1870/1875 [============================>.] - ETA: 0s - loss: 0.1304 - accuracy: 0.9622\n",
      "Epoch 2: val_accuracy improved from 0.95300 to 0.96370, saving model to mnist_functional_template_v1.h5\n",
      "1875/1875 [==============================] - 19s 10ms/step - loss: 0.1306 - accuracy: 0.9621 - val_loss: 0.1202 - val_accuracy: 0.9637\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2f00a96d0>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train the model on the training data (X_train and y_train) with the following configurations:\n",
    "# - Validation data: (X_test, y_test), used to evaluate the model after each epoch.\n",
    "# - Number of epochs: 2, specifying how many times the entire training dataset is passed through the model.\n",
    "# - Batch size: 32, indicating the number of samples per gradient update during training.\n",
    "# - Callbacks: ModelCheckpoint and EarlyStopping, used for saving the best model and stopping early to prevent overfitting.\n",
    "model.fit(X_train, y_train,\n",
    "          validation_data=(X_test, y_test),\n",
    "          epochs=2,\n",
    "          batch_size=32,\n",
    "          callbacks=[model_checkpoint, early_stopping])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c0efa18c-462a-424e-8b3a-246d2cf18ac6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the trained model to a file named 'mnist_leaky_relu_functional_2b_v1.h5'.\n",
    "# This file will contain the model architecture, weights, and configuration.\n",
    "model.save('mnist_functional_template_v1.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "93f2014d-850c-4448-9b05-bfc3bb6108d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 10808\n",
      "-rw-r--r--@ 1 vidyadharbendre  staff    12924 Mar 21 05:40 Functional_2a.ipynb\n",
      "-rw-r--r--@ 1 vidyadharbendre  staff    13811 Mar 21 05:50 Functional_2b.ipynb\n",
      "-rw-r--r--@ 1 vidyadharbendre  staff    20105 Mar 21 06:06 Functional_Template_v1.ipynb\n",
      "-rw-r--r--@ 1 vidyadharbendre  staff    21528 Mar 20 20:16 Sequential_1a.ipynb\n",
      "-rw-r--r--@ 1 vidyadharbendre  staff    25555 Mar 20 21:00 Sequential_1b.ipynb\n",
      "-rw-r--r--@ 1 vidyadharbendre  staff    25555 Mar 20 21:00 Sequential_1c.ipynb\n",
      "-rw-r--r--@ 1 vidyadharbendre  staff    12703 Mar 20 22:22 Sequential_1d.ipynb\n",
      "-rw-r--r--@ 1 vidyadharbendre  staff    12726 Mar 20 22:36 Sequential_1e.ipynb\n",
      "-rw-r--r--@ 1 vidyadharbendre  staff    12726 Mar 20 22:36 Sequential_Template_v1.ipynb\n",
      "-rw-r--r--@ 1 vidyadharbendre  staff  2325560 Mar 21 06:06 mnist_functional_template_v1.h5\n",
      "-rw-r--r--@ 1 vidyadharbendre  staff  2325560 Mar 21 06:04 mnist_leaky_relu_v1.h5\n"
     ]
    }
   ],
   "source": [
    "!ls -l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0f7fec43-72e7-4eac-9b4d-b520dc17c09f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 784)]             0         \n",
      "                                                                 \n",
      " first_layer (Dense)         (None, 512)               401920    \n",
      "                                                                 \n",
      " second_layer (Dense)        (None, 256)               131328    \n",
      "                                                                 \n",
      " third_layer (Dense)         (None, 128)               32896     \n",
      "                                                                 \n",
      " fourth_layer (Dense)        (None, 64)                8256      \n",
      "                                                                 \n",
      " dense (Dense)               (None, 10)                650       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 575,050\n",
      "Trainable params: 575,050\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "#from tensorflow.keras.models import load_model\n",
    "\n",
    "# Load the previously saved model from the file 'mnist_functional_template_v1.h5'.\n",
    "model = load_model('mnist_functional_template_v1.h5')\n",
    "\n",
    "# Print a summary of the loaded model, which provides information about the model's architecture,\n",
    "# including the type and shape of each layer, as well as the number of parameters in each layer.\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f4b768fb-13ff-4c48-9250-fd92713c5de8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Model was constructed with shape (None, 784) for input KerasTensor(type_spec=TensorSpec(shape=(None, 784), dtype=tf.float32, name='input_1'), name='input_1', description=\"created by layer 'input_1'\"), but it was called on an input with incompatible shape (None,).\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    File \"/Users/vidyadharbendre/miniforge3/lib/python3.9/site-packages/keras/engine/training.py\", line 1845, in predict_function  *\n        return step_function(self, iterator)\n    File \"/Users/vidyadharbendre/miniforge3/lib/python3.9/site-packages/keras/engine/training.py\", line 1834, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/Users/vidyadharbendre/miniforge3/lib/python3.9/site-packages/keras/engine/training.py\", line 1823, in run_step  **\n        outputs = model.predict_step(data)\n    File \"/Users/vidyadharbendre/miniforge3/lib/python3.9/site-packages/keras/engine/training.py\", line 1791, in predict_step\n        return self(x, training=False)\n    File \"/Users/vidyadharbendre/miniforge3/lib/python3.9/site-packages/keras/utils/traceback_utils.py\", line 67, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"/Users/vidyadharbendre/miniforge3/lib/python3.9/site-packages/keras/engine/input_spec.py\", line 228, in assert_input_compatibility\n        raise ValueError(f'Input {input_index} of layer \"{layer_name}\" '\n\n    ValueError: Exception encountered when calling layer \"model\" (type Functional).\n    \n    Input 0 of layer \"first_layer\" is incompatible with the layer: expected min_ndim=2, found ndim=1. Full shape received: (None,)\n    \n    Call arguments received by layer \"model\" (type Functional):\n      • inputs=tf.Tensor(shape=(None,), dtype=float32)\n      • training=False\n      • mask=None\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[26], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_test\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniforge3/lib/python3.9/site-packages/keras/utils/traceback_utils.py:67\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# pylint: disable=broad-except\u001b[39;00m\n\u001b[1;32m     66\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m---> 67\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     68\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     69\u001b[0m   \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m/var/folders/kd/yddgdhm92qxgkw2js4t89ksr0000gn/T/__autograph_generated_filebhwgxm8b.py:15\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__predict_function\u001b[0;34m(iterator)\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     14\u001b[0m     do_return \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m---> 15\u001b[0m     retval_ \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(step_function), (ag__\u001b[38;5;241m.\u001b[39mld(\u001b[38;5;28mself\u001b[39m), ag__\u001b[38;5;241m.\u001b[39mld(iterator)), \u001b[38;5;28;01mNone\u001b[39;00m, fscope)\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[1;32m     17\u001b[0m     do_return \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "\u001b[0;31mValueError\u001b[0m: in user code:\n\n    File \"/Users/vidyadharbendre/miniforge3/lib/python3.9/site-packages/keras/engine/training.py\", line 1845, in predict_function  *\n        return step_function(self, iterator)\n    File \"/Users/vidyadharbendre/miniforge3/lib/python3.9/site-packages/keras/engine/training.py\", line 1834, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/Users/vidyadharbendre/miniforge3/lib/python3.9/site-packages/keras/engine/training.py\", line 1823, in run_step  **\n        outputs = model.predict_step(data)\n    File \"/Users/vidyadharbendre/miniforge3/lib/python3.9/site-packages/keras/engine/training.py\", line 1791, in predict_step\n        return self(x, training=False)\n    File \"/Users/vidyadharbendre/miniforge3/lib/python3.9/site-packages/keras/utils/traceback_utils.py\", line 67, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"/Users/vidyadharbendre/miniforge3/lib/python3.9/site-packages/keras/engine/input_spec.py\", line 228, in assert_input_compatibility\n        raise ValueError(f'Input {input_index} of layer \"{layer_name}\" '\n\n    ValueError: Exception encountered when calling layer \"model\" (type Functional).\n    \n    Input 0 of layer \"first_layer\" is incompatible with the layer: expected min_ndim=2, found ndim=1. Full shape received: (None,)\n    \n    Call arguments received by layer \"model\" (type Functional):\n      • inputs=tf.Tensor(shape=(None,), dtype=float32)\n      • training=False\n      • mask=None\n"
     ]
    }
   ],
   "source": [
    "model.predict(X_test[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "e80acae3-82a7-4e4a-8407-c94361b246cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(784,)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test[3707].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "cdef9aaa-fb1f-48b1-917c-9b3d33ac104c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 784)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_data = np.expand_dims(X_test[3707], axis=0)\n",
    "input_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "16298a86-47bb-424b-a26b-2d1ee0e32c4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 16ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(1, 10)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred = model.predict(input_data)\n",
    "pred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "24ac315c-1bad-4fb5-a40a-1e4b347b4567",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([5.1036335e-05, 7.0895231e-04, 2.6587194e-03, 1.7063377e-02,\n",
       "       3.0483559e-05, 6.3528982e-04, 4.9005089e-06, 2.2001520e-03,\n",
       "       9.7150797e-01, 5.1391483e-03], dtype=float32)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "627d30c7-8644-45b6-875a-f6b6c51c07d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argmax(pred[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "354eecaa-eb72-4819-a823-da311727f02d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.97150797"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.max(pred[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "1bd9d166-dfc1-4e29-8e5b-c061a10366ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argmax(y_test[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "e21e3ec7-995b-4b4d-906e-4995656a0b05",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Reshape the image data back to its original shape (28x28)\n",
    "image = X_test[0].reshape(28, 28)\n",
    "\n",
    "# Display the image using plt.imshow()\n",
    "plt.imshow(image, cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "592d3ec3-ca18-4c12-a50c-e001cf014bf8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
