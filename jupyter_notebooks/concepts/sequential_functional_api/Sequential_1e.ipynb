{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "484d8695-cec3-41d0-9a9a-c28d849c3596",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2baf7efc-9438-4571-8fea-826da0d39d49",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.datasets import mnist\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.backend import clear_session\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Reshape, Dense, BatchNormalization, LeakyReLU\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b91d1831-f6d0-488d-b94f-3b0ad651c439",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Download dataset\n",
    "(X_train, y_train),(X_test, y_test) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e6ad17d6-e14f-4f61-8bb0-4a6f9a7b78bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.reshape(-1, 28*28).astype(\"float32\")/255.0\n",
    "X_test = X_test.reshape(-1, 28*28).astype(\"float32\")/255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "88ccb6da-40c3-4c4e-9840-1a7bdd50d497",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((60000, 784), (60000,), (10000, 784), (10000,))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, y_train.shape, X_test.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1baec0ae-d1e3-4f00-b0c6-203b978ed078",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Label for an example\n",
    "y_test[3707]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b8ef7a62-7f53-460b-a5d0-35f864054e04",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = tf.keras.utils.to_categorical(y_train, num_classes=10)\n",
    "y_test = tf.keras.utils.to_categorical(y_test, num_classes=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bcf19560-8792-44e4-9abc-36d6563a9d55",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 0., 0., 1., 0., 0., 0., 0.], dtype=float32)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Label for an example\n",
    "y_test[2805]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a3b04720-77ad-46b1-ba2a-a14764894f36",
   "metadata": {},
   "outputs": [],
   "source": [
    "### version -1 ###\n",
    "clear_session()\n",
    "\n",
    "#Initialize Sequential model\n",
    "model = Sequential(\n",
    "    [\n",
    "        #Reshape data from 2D to 1D -> 28x28 to 784\n",
    "        Dense(512, activation=\"relu\", input_dim=784),\n",
    "        Dense(256, activation=\"relu\", name=\"second_layer\"),\n",
    "        Dense(128, activation=\"relu\", name=\"third_layer\"),\n",
    "        Dense(64, activation=\"relu\", name=\"fourth_layer\"),\n",
    "        #Add OUTPUT layer\n",
    "        Dense(10, activation='softmax') \n",
    "    ]\n",
    "    \n",
    ")\n",
    "\n",
    "#Compile the model\n",
    "model.compile(optimizer='sgd', loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e0d3967a-56e4-4277-9c2d-6a01a067e74b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 512)               401920    \n",
      "                                                                 \n",
      " second_layer (Dense)        (None, 256)               131328    \n",
      "                                                                 \n",
      " third_layer (Dense)         (None, 128)               32896     \n",
      "                                                                 \n",
      " fourth_layer (Dense)        (None, 64)                8256      \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 10)                650       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 575,050\n",
      "Trainable params: 575,050\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#Review model\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "128941e0-81df-49a1-b020-1771924ed4b3",
   "metadata": {},
   "source": [
    "In the context of machine learning, both model checkpoints and callbacks are tools used to improve the training process of neural networks, particularly in deep learning frameworks like TensorFlow and PyTorch. However, they serve different purposes:\n",
    "\n",
    "Model Checkpoint:\n",
    "\n",
    "A model checkpoint is a feature used to save the model's current weights or entire state at certain intervals during training.\n",
    "The primary purpose of a model checkpoint is to save the model's progress periodically so that it can be restored or used later for inference or further training.\n",
    "Model checkpoints are typically used to save the best-performing model based on a specified metric, such as validation accuracy or loss. This ensures that you retain the best version of the model throughout the training process.\n",
    "Checkpoints are especially useful for long training processes where interruptions or failures may occur, allowing you to resume training from the last saved checkpoint rather than starting from scratch.\n",
    "Callback:\n",
    "\n",
    "A callback is a function or set of functions that are executed at specific points during the training process, such as at the beginning or end of an epoch or after a batch of data is processed.\n",
    "Callbacks are more versatile and can perform various tasks during training, such as logging training metrics, adjusting learning rates dynamically, implementing early stopping, or saving model checkpoints.\n",
    "While model checkpoints are a specific type of callback used for saving model weights, callbacks can perform a wide range of additional functions to customize the training process according to your specific needs.\n",
    "Callbacks can be defined by the user or provided by the deep learning framework as pre-defined functions. Users can also create custom callbacks to implement specific behaviors not covered by built-in callbacks.\n",
    "In summary, a model checkpoint is a type of callback used specifically for saving model weights or state during training, while callbacks encompass a broader range of functions that can be executed at various stages of the training process to customize and enhance the training procedure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1c15c4b0-c8f5-4c4b-8641-d763c3095da5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ModelCheckpoint callback to save the best model based on validation accuracy\n",
    "model_checkpoint = ModelCheckpoint(\n",
    "    'mnist_leaky_relu_v1.h5',  # File path to save the model\n",
    "    save_best_only=True,       # Save only the best model based on monitored metric\n",
    "    monitor='val_accuracy',    # Metric to monitor for determining the best model\n",
    "    mode='max',                # Mode for determining the best model ('max' or 'min')\n",
    "    verbose=1                  # Verbosity mode (0 or 1)\n",
    ")\n",
    "\n",
    "# EarlyStopping callback to stop training when the monitored metric stops improving\n",
    "early_stopping = EarlyStopping(\n",
    "    monitor='val_loss',        # Metric to monitor for early stopping\n",
    "    patience=5,                # Number of epochs with no improvement after which training will be stopped\n",
    "    verbose=1,                 # Verbosity mode (0 or 1)\n",
    "    restore_best_weights=True  # Whether to restore model weights from the epoch with the best value of the monitored quantity\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c2db5a9-573f-4053-9f4b-38aee40c4a76",
   "metadata": {},
   "source": [
    "Using both callbacks allows you to save the best model based on a monitored metric while also stopping the training process if the model's performance on a validation set stops improving, thereby preventing overfitting. This combination can help you find the best-performing model while avoiding unnecessary training epochs. It's a recommended practice for many training scenarios."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "034681c2-b161-44a9-918a-223a831c970f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-20 22:34:04.953662: W tensorflow/core/platform/profile_utils/cpu_utils.cc:128] Failed to get CPU frequency: 0 Hz\n",
      "2024-03-20 22:34:05.071841: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1871/1875 [============================>.] - ETA: 0s - loss: 0.5573 - accuracy: 0.8480"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-20 22:34:23.775794: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1: val_accuracy improved from -inf to 0.92470, saving model to mnist_leaky_relu_v1.h5\n",
      "1875/1875 [==============================] - 21s 10ms/step - loss: 0.5567 - accuracy: 0.8482 - val_loss: 0.2502 - val_accuracy: 0.9247\n",
      "Epoch 2/2\n",
      "1870/1875 [============================>.] - ETA: 0s - loss: 0.2147 - accuracy: 0.9365\n",
      "Epoch 2: val_accuracy improved from 0.92470 to 0.94960, saving model to mnist_leaky_relu_v1.h5\n",
      "1875/1875 [==============================] - 19s 10ms/step - loss: 0.2145 - accuracy: 0.9366 - val_loss: 0.1697 - val_accuracy: 0.9496\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x173231d90>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train,y_train,          \n",
    "          validation_data=(X_test, y_test),\n",
    "          epochs=2,\n",
    "          batch_size=32, \n",
    "          callbacks=[model_checkpoint, early_stopping])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "c0efa18c-462a-424e-8b3a-246d2cf18ac6",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('mnist_leaky_relu_sequential_1a_v1.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93f2014d-850c-4448-9b05-bfc3bb6108d1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
