{"cells":[{"cell_type":"markdown","metadata":{"id":"Sqzm5Om4rEvq"},"source":["#### Download a trained model"]},{"cell_type":"markdown","metadata":{"id":"zdkJQ2MuYwMh"},"source":["We will download a trained model from [TensorFlow detection model zoo](https://github.com/tensorflow/models/blob/master/research/object_detection/g3doc/detection_model_zoo.md#coco-trained-models-coco-models). If you already have a trained model then you can use the same here."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"IhwY3bSIYhbm"},"outputs":[],"source":["#Get trained model\n","!wget -q http://download.tensorflow.org/models/object_detection/ssd_mobilenet_v1_coco_2018_01_28.tar.gz"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"EHsX5ZkvZ6pJ"},"outputs":[],"source":["!ls -l"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ujeoCooOZ4Fo"},"outputs":[],"source":["#Unzip the file\n","!tar -xf ssd_mobilenet_v1_coco_2018_01_28.tar.gz"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"KrdlbRHTaBiz"},"outputs":[],"source":["#check the unzipped files in the folder\n","!ls -l ssd_mobilenet_v1_coco_2018_01_28"]},{"cell_type":"markdown","metadata":{"id":"y2L_YpSmaKh-"},"source":["When we export the model (after training), we will get same set of files."]},{"cell_type":"markdown","metadata":{"id":"JL-VU8HwabXj"},"source":["#### Load Model"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"8NdJs8LqSAJb"},"outputs":[],"source":["#This code will work with tf 2.x\n","import tensorflow as tf"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"PxNGLv_xWhaO"},"outputs":[],"source":["#Check the tf version\n","tf.__version__"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"by5hnBF5R-ev"},"outputs":[],"source":["#In tf2, we will use saved model rather than frozen_inference_graph.pb\n","model = tf.saved_model.load('ssd_mobilenet_v1_coco_2018_01_28/saved_model')\n","model = model.signatures['serving_default']"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ep4Xz-sxhCmC"},"outputs":[],"source":["#Check model's input\n","model.inputs"]},{"cell_type":"markdown","metadata":{"id":"Pti2aYT-hNqn"},"source":["Here the model input tensor's name is 'image_tensor' and it has a 4D shape (first dimension is for batch size i.e how many images we will feed)."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"rj0QqON5hqwO"},"outputs":[],"source":["#Check model's output tensors\n","model.outputs"]},{"cell_type":"markdown","metadata":{"id":"wHjO7bcahnYi"},"source":["How to understand 4 outputs here:\n","\n","\n","\n","1.   **num_detections** : Number of prediction boxes we are getting from our model. We limit number of predictions in model configuration file. In this model, output will have top 100 predictions (out of 1000s of anchor boxes). Please note that we get this output after Non-Maximum supression (NMS) step has been completed.\n","2.   **detection_classes** : Index of the class with highest probability for each predicted box. These index values should be matched with index created using Label Encoder during training time. The values will between 1 to number of classes.\n","3.   **detection_scores** : Probability value for highest probability class for each box. The value will be between 0 to 1. This indicates how confident model of a real object in the box.\n","4.   **detection_boxes** : Boundary box co-ordinates for each predicted box. For each predicted box, we get 4 outputs i.e ymin, xmin, ymax, xmax. Please note that these are normalized values.\n","\n"]},{"cell_type":"markdown","metadata":{"id":"q0pTF60YSNxZ"},"source":["#### Load Class labels"]},{"cell_type":"markdown","metadata":{"id":"f11_p-MBSQtp"},"source":["Label dictionary (class index to class name mapping) should be taken from training module. Here is the dictionary which was used for this model."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"LszBHGAISPka"},"outputs":[],"source":["all_classes = {1 : 'person' , 2: 'bicycle' , 3: 'car' , 4: 'motorcycle' , 5: 'airplane' , 6: 'bus' , 7: 'train' , \n","               8: 'truck' , 9: 'boat' , 10: 'traffic light' , 11: 'fire hydrant' , 13: 'stop sign' , 14: 'parking meter' , \n","               15: 'bench' , 16: 'bird' , 17: 'cat' , 18: 'dog' , 19: 'horse' , 20: 'sheep' , 21: 'cow' , 22: 'elephant' , \n","               23: 'bear' , 24: 'zebra' , 25: 'giraffe' , 27: 'backpack' , 28: 'umbrella' , 31: 'handbag' , 32: 'tie' , \n","               33: 'suitcase' , 34: 'frisbee' , 35: 'skis' , 36: 'snowboard' , 37: 'sports ball' , 38: 'kite' , \n","               39: 'baseball bat' , 40: 'baseball glove' , 41: 'skateboard' , 42: 'surfboard' , 43: 'tennis racket' , \n","               44: 'bottle' , 46: 'wine glass' , 47: 'cup' , 48: 'fork' , 49: 'knife' , 50: 'spoon' , 51: 'bowl' , \n","               52: 'banana' , 53: 'apple' , 54: 'sandwich' , 55: 'orange' , 56: 'broccoli' , 57: 'carrot' , 58: 'hot dog' , \n","               59: 'pizza' , 60: 'donut' , 61: 'cake' , 62: 'chair' , 63: 'couch' , 64: 'potted plant' , 65: 'bed' , \n","               67: 'dining table' , 70: 'toilet' , 72: 'tv' , 73: 'laptop' , 74: 'mouse' , 75: 'remote' , 76: 'keyboard' , \n","               77: 'cell phone' , 78: 'microwave' , 79: 'oven' , 80: 'toaster' , 81: 'sink' , 82: 'refrigerator' , \n","               84: 'book' , 85: 'clock' , 86: 'vase' , 87: 'scissors' , 88: 'teddy bear' , 89: 'hair drier' , 90: 'toothbrush'}"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"XZP_JtLiVXEf"},"outputs":[],"source":["all_classes[15]"]},{"cell_type":"markdown","metadata":{"id":"PALYIrj9sSrN"},"source":["#### Model Prediction"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"xnPdSqAjoayD"},"outputs":[],"source":["#Function to get predictions from a Detection model\n","def detector_prediction(image_file, confidence_threshold=0.5):\n","\n","    \"\"\"\n","    image_file: File path of the image for which prediction needs to be done\n","    confidence_threshold: Minimum confidence/probability for prediction to be considered\n","    \"\"\"\n","    #Load image\n","    img = tf.keras.preprocessing.image.load_img(image_file)\n","    \n","    #Convert to numpy array\n","    img_array = tf.keras.preprocessing.image.img_to_array(img).astype('uint8')\n","    #Make it a batch of one example\n","    img_array = tf.expand_dims(img_array, axis=0)\n","\n","    #Prediction\n","    output = model(img_array) #get list of tensors discussed above as output\n","    detection_scores = output['detection_scores'].numpy()[0] #get detection scores\n","    detection_classes = output['detection_classes'].numpy()[0]\n","    detection_boxes = output['detection_boxes'].numpy()[0]\n","\n","    #Select predictions for which probability is higher than confidence_threshold\n","    selected_predictions = detection_scores >= confidence_threshold\n","\n","    selected_prediction_scores = detection_scores[selected_predictions]\n","    selected_prediction_classes = detection_classes[selected_predictions]\n","    selected_prediction_boxes = detection_boxes[selected_predictions]\n","\n","    #De-normalize box co-ordinates (multiply x-coordinates by image width and y-coords by image height)\n","    img_w, img_h = img.size\n","\n","    for i in range(selected_prediction_boxes.shape[0]):\n","        \n","        selected_prediction_boxes[i,0] *= img_h #ymin * img_w\n","        selected_prediction_boxes[i,1] *= img_w #xmin * img_h\n","        selected_prediction_boxes[i,2] *= img_h #ymax * img_w\n","        selected_prediction_boxes[i,3] *= img_w #xmax * img_h\n","\n","    #Make all co-ordinates as integer\n","    selected_prediction_boxes= selected_prediction_boxes.astype(int)\n","\n","    #Convert class indexes to actual class labels\n","    predicted_classes = []\n","    for i in range(selected_prediction_classes.shape[0]):\n","        predicted_classes.append(all_classes[int(selected_prediction_classes[i])])\n","\n","    #Number of predictions\n","    selected_num_predictions = selected_prediction_boxes.shape[0]\n","\n","    return {'Total Predictions': selected_num_predictions,\n","            'Scores': selected_prediction_scores, \n","            'Classes': predicted_classes, \n","            'Box coordinates': selected_prediction_boxes}"]},{"cell_type":"markdown","metadata":{"id":"zBJxH1CUKzag"},"source":["Let's download couple of images for which we will do predictions."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"I9-Rax5xLCcZ"},"outputs":[],"source":["!wget https://github.com/tensorflow/models/raw/master/research/object_detection/test_images/image1.jpg --quiet\n","!wget https://github.com/tensorflow/models/raw/master/research/object_detection/test_images/image2.jpg --quiet"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"G3ebquawu-Rc"},"outputs":[],"source":["!ls -l"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"sPbIDpAGxeBC"},"outputs":[],"source":["#Model predictions for image1.jpg\n","detector_prediction('image2.jpg', confidence_threshold=0.3)"]},{"cell_type":"markdown","metadata":{"id":"pziK2r8-MOQr"},"source":["#### Visualizing Model Prediction"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"jjaKo63LMf7B"},"outputs":[],"source":["import cv2\n","from matplotlib import pyplot as plt"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"HLfLuQFgMQgJ"},"outputs":[],"source":["def visualize_output(image_file, confidence_threshold=0.5):\n","\n","    #Call model prediction function above\n","    output = detector_prediction(image_file, confidence_threshold=confidence_threshold)\n","\n","    #Read image\n","    img = cv2.imread(image_file)\n","\n","    #Draw rectangle for predicted boxes, also add predicted classes\n","    for i in range(output['Box coordinates'].shape[0]):\n","\n","        box = output['Box coordinates'][i]\n","        \n","        #Draw rectangle \n","        img = cv2.rectangle(img, (box[1], box[0]), (box[3], box[2]), (0,255,0), 2)\n","        \n","        #Add Label - Class name and confidence level\n","        label = output['Classes'][i] + ': ' + str(round(output['Scores'][i],2))\n","        img = cv2.putText(img, label, (box[1], box[0]-10), cv2.FONT_HERSHEY_SIMPLEX, 1, (255,255,255), 2, cv2.LINE_AA)\n","    \n","    #Conver BGR image to RGB to use with Matplotlib\n","    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n","\n","    #Display image\n","    plt.figure(figsize=(12,8))\n","    plt.imshow(img)\n","    plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"6c0umKw2O74F"},"outputs":[],"source":["#Visualize first image\n","visualize_output('image1.jpg')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Sv06rWVDsVZH"},"outputs":[],"source":["#Visualize second image\n","visualize_output('image2.jpg', confidence_threshold=0.3)"]}],"metadata":{"colab":{"collapsed_sections":[],"name":"2. Model Prediction : Pre-trained Model.ipynb","private_outputs":true,"provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"}},"nbformat":4,"nbformat_minor":0}
