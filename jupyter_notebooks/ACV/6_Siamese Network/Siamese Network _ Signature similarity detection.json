{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Siamese Network : Signature similarity detection","private_outputs":true,"provenance":[],"collapsed_sections":["4xXYjsMUAy7y","X28jYq8NqkmF","_4c__eXSxXNW"]},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.5"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"GTEqqZMIiom-"},"source":["#### Download data\n","\n"]},{"cell_type":"markdown","metadata":{"id":"2XSU2sC0zj_q"},"source":["Data for this exercise is available on [this](https://drive.google.com/open?id=0B29vNACcjvzVc1RfVkg5dUh2b1E) Google Drive link. \n","\n","\n","\n","1.   We will download the data using *googledrivedownloader* package (can be downloaded manually as well).\n","2.   The database dataset contains the signatures of **260 persons**.\n","3.   Out of 260, 100 were signed in **Bengali** and 160 are signed in **Hindi**.\n","4.   For each signers, there are **24 genuine** and **30 forged** signatures available. \n","5.   In Bengali, we have 2400 (100 x 24) genuine and 3000 (100 x 30) forged signatures.\n","6.   In Hindi, we have 3840 (160 x 24) genuine 4800 (160 x 30) forged signatures.\n","\n","**Paper reference**: https://arxiv.org/pdf/1707.02131.pdf\n","\n"]},{"cell_type":"code","metadata":{"id":"TWu5sCKTn-wq"},"source":["#Install package\n","!pip install googledrivedownloader --quiet"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"SLOYv28B0ZMm"},"source":["from google_drive_downloader import GoogleDriveDownloader as gdd"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"go2w2yTW1XRR"},"source":["#Download file\n","gdd.download_file_from_google_drive(file_id='0B29vNACcjvzVc1RfVkg5dUh2b1E', #file id as per link\n","                                    dest_path='./BHSig260.zip', #File name given to downloaded file\n","                                    unzip=True) #Unzip the downloaded file"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"kphVZgEZ6JoN"},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"SvSAyKMj0o_t"},"source":["#Check if the file exists\n","!ls -l"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"UjjagafaqvS4"},"source":["!unzip /content/drive/MyDrive/BHSig260.zip "],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"q9WuX2d-864V"},"source":["#Check dataset folder\n","!ls -l BHSig260"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"QEjneSevCThU"},"source":["!ls -l BHSig260/Hindi"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"stdqGXfq8_Go"},"source":["#Check data in Hindi folder\n","!ls -l BHSig260/Hindi/012"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Y8wh90Ho6T2x"},"source":["#### Data preparation\n","\n","We will use only Hindi signatures for this exercise."]},{"cell_type":"code","metadata":{"id":"GxB-WZlg6fZO"},"source":["import os"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"smlHEXb86oeU"},"source":["Get list of signature directories (1 directory per person)"]},{"cell_type":"code","metadata":{"id":"Q7gAhIAW6nFI"},"source":["#Path to Hindi signatures\n","path = 'BHSig260/Hindi/'\n","\n","#Get the list of all directories and sort them\n","dir_list = next(os.walk(path))[1]\n","dir_list.sort()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"b4IPVn_n7VcY"},"source":["#List of directories\n","print(dir_list)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"S18S_uQ77kuC"},"source":["Get signature filenames for each person (1 Directory).\n","- For each person, first 30 pictures are forged signature\n","- Last 24 pictures in the directory are genuine"]},{"cell_type":"code","metadata":{"id":"1oCeEk0w74Of"},"source":["#Start with empty list of original and fake signatures\n","genuine_signs = []\n","forged_signs = []"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"GTzncjjA8GrY"},"source":["#Loop through each directory\n","for directory in dir_list:\n","\n","    #Read all image file names in the directory\n","    images = os.listdir(path+directory)\n","    images.sort()\n","\n","    #Add path to image name\n","    images = [path+directory + '/'+ x for x in images]\n","\n","    #First 30 signs are forged\n","    forged_signs.append(images[:30])\n","    #Last 24 signs are genuine\n","    genuine_signs.append(images[30:])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"oXUGc3j48xpD"},"source":["#Check if we have 160 people's genuine and forged signatures\n","print('Number of people with genuine signs:', len(genuine_signs))\n","print('Number of people with forged signs:', len(forged_signs))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"rbLrF7UIDGFI"},"source":["len(genuine_signs[10])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"LBAcWD3878Aq"},"source":["len(forged_signs[10])"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"KoVk7yzc9V7Z"},"source":["Split between Training and Test. We will use first 80% directories for training and last 20% for test."]},{"cell_type":"code","metadata":{"id":"1bbIKdWz9iLf"},"source":["train_g, test_g = genuine_signs[:128], genuine_signs[128:]\n","train_f, test_f = forged_signs[:128], forged_signs[128:]"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"GJ7CheTq979y"},"source":["#### Visualize Signatures"]},{"cell_type":"code","metadata":{"id":"Pt-sQ4O1_bJw"},"source":["import tensorflow as tf\n","import numpy as np\n","from matplotlib import pyplot as plt\n","from tqdm import tqdm"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"dSxGYc3ZnWE5"},"source":["def visualize_signatures():\n","\n","    \"\"\"\n","    1. Randomly select a person id\n","    2. Show two genuine signatures for the person\n","    3. Show one forged signature for the same person\n","    \"\"\"\n","    \n","    #Pick up a person from 160 people\n","    person_id = np.random.randint(0, len(genuine_signs))\n","\n","    #Read genuine signature pics\n","    genuine1, genuine2 = np.random.randint(0, 24, 2) #Get two pics randomly\n","    original_img = tf.keras.preprocessing.image.load_img(genuine_signs[person_id][genuine1])#, color_mode='grayscale')\n","    genuine_img = tf.keras.preprocessing.image.load_img(genuine_signs[person_id][genuine2])#, color_mode='grayscale')\n","\n","    #Read forged signature of same person\n","    forged1 = np.random.randint(0, 30)\n","    forged_img = tf.keras.preprocessing.image.load_img(forged_signs[person_id][forged1])#, color_mode='grayscale')\n","\n","    #Display pictures    \n","    fig, (ax1, ax2, ax3) = plt.subplots(1, 3, figsize = (15, 10))\n","\n","    ax1.set_title('Genuine sign')\n","    ax1.imshow(original_img, cmap = 'gray')\n","    ax1.axis('off')\n","\n","    ax2.set_title('Genuine sign')\n","    ax2.imshow(genuine_img, cmap = 'gray')\n","    ax2.axis('off')\n","\n","    ax3.set_title('Forged sign')\n","    ax3.imshow(forged_img, cmap = 'gray')\n","    #ax3.axis('off')\n","\n","    plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ODvJ52T3-AMu"},"source":["visualize_signatures()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"4YAIYkwwB-5Z"},"source":["#### Building signature pairs"]},{"cell_type":"code","metadata":{"id":"MYpcD7NMC7z5"},"source":["#n(n-1)/2\n","24*23/2"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"YmWAXweiCeRI"},"source":["Siamese network requires **two inputs** (rather than one we use with other models). In this case, the two input could be a \n","1. Combination of **genuine-genuine** signatures\n","2. Combination of **genuine-forged** signatures\n","\n","In the dataset, for each person, we have 24 genuine signatures and 30 forged signatures."]},{"cell_type":"markdown","metadata":{"id":"SMLXIdNODe0U"},"source":["How many pairs can we create for model training. For each person...\n","\n","1. We can have 24 C 2 i.e 276 **genuine-genuine** pairs\n","2. We can have 24 x 30 = 720 **genuine-forged** pairs\n","\n","This will make distribution to be 276:720 *i.e* 1:3 (approximate). \n","\n","To make the distribution even between different type of pairs, we will randomly take only 12 forged pictures (out of 30). This will make us have 24 x 12 = **288** genuine-forged pairs for each person."]},{"cell_type":"markdown","metadata":{"id":"LG06fc0SFE6G"},"source":["**Question: How many pairs we will have in training and test dataset?**"]},{"cell_type":"markdown","metadata":{"id":"3xFThzdqGSRZ"},"source":["Build genuine-genuine pairs"]},{"cell_type":"code","metadata":{"id":"0Cgp5DiTGUWd"},"source":["def build_genuine_pairs(sig_list):\n","\n","    pairs_list = []\n","\n","    for person_id in range(len(sig_list)):\n","\n","        for i in range(len(sig_list[0])-1):\n","            for j in range(i+1, len(sig_list[0])):\n","\n","                pairs_list.append([sig_list[person_id][i], sig_list[person_id][j]])\n","    \n","    return pairs_list"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"9EZaAnpNHaWo"},"source":["#Build training and test pairs\n","train_g_g_pairs = build_genuine_pairs(train_g)\n","test_g_g_pairs = build_genuine_pairs(test_g)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"fnYj19wtHogp"},"source":["#Check number of pairs in training and test\n","print('Number of genuine pairs in training set:', len(train_g_g_pairs))\n","print('Number of genuine pairs in test set:', len(test_g_g_pairs))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"48WUE4YgeQEf"},"source":["128*276"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"IXAvUc6zID7m"},"source":["Build genuine-fake pairs"]},{"cell_type":"code","metadata":{"id":"T-s1Yr8nIGMA"},"source":["def build_gen_forged_pairs(gen_sigs, forged_sigs):\n","\n","    pairs_list = []\n","\n","    for person_id in range(len(gen_sigs)):\n","\n","        #Let's pickup 12 random numbers for forged signatures\n","        forged_ids = np.random.randint(0, len(forged_sigs[0]), 12)\n","\n","        for i in range(len(gen_sigs[0])):\n","            for j in forged_ids:\n","                pairs_list.append([gen_sigs[person_id][i], forged_sigs[person_id][j]])\n","    \n","    return pairs_list"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"6FdgxIqjJYof"},"source":["#Build training and test pairs\n","train_g_f_pairs = build_gen_forged_pairs(train_g, train_f)\n","test_g_f_pairs = build_gen_forged_pairs(test_g, test_f)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ZaagN-Z1J_o8"},"source":["#Check number of pairs in training and test\n","print('Number of genuine-forged pairs in training set:', len(train_g_f_pairs))\n","print('Number of genuine-forged pairs in test set:', len(test_g_f_pairs))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"A1_7oZGPeg-L"},"source":["#Total number of examples in training\n","len(train_g_g_pairs) +  len(train_g_f_pairs)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"IQOsoWD-HmcI"},"source":["#Total number of examples in Test\n","len(test_g_g_pairs) +  len(test_g_f_pairs)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"WWT_Wb_OLaBk"},"source":["#### Build Batch Generator"]},{"cell_type":"code","metadata":{"id":"nE5HMf3XZLzw"},"source":["img_width = 330\n","img_height = 100"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"7Ac1ky-FLcV0"},"source":["def batch_generator(gen_gen_list, gen_forged_list, batch_size=32):\n","\n","\n","    while True:\n","\n","        first_img_array = np.zeros((batch_size, img_height, img_width, 3))\n","        second_img_array = np.zeros((batch_size, img_height, img_width, 3))\n","        batch_labels = np.zeros((batch_size, 1))\n","\n","        #Generate batch_size ids for both type of pairs\n","        gen_gen_pair_idx = np.random.randint(0, len(gen_gen_list), batch_size//2)\n","        gen_forged_pair_idx = np.random.randint(0, len(gen_forged_list), batch_size//2)\n","\n","        for i in range(batch_size//2):\n","\n","            #Get images from gen_gen pair\n","            gg_id = gen_gen_pair_idx[i]\n","            first_img = tf.keras.preprocessing.image.load_img(gen_gen_list[gg_id][0], target_size=(img_height, img_width))\n","            second_img = tf.keras.preprocessing.image.load_img(gen_gen_list[gg_id][1], target_size=(img_height, img_width))\n","            \n","            first_img_array[2*i] = tf.keras.preprocessing.image.img_to_array(first_img)\n","            second_img_array[2*i] = tf.keras.preprocessing.image.img_to_array(second_img)\n","\n","            #Genuine genuine pair will be a given a label of '1'\n","            batch_labels[2*i] = 1\n","\n","            #Get images from gen_forged pair\n","            gf_id = gen_forged_pair_idx[i]\n","            first_img = tf.keras.preprocessing.image.load_img(gen_forged_list[gf_id][0], target_size=(img_height, img_width))\n","            second_img = tf.keras.preprocessing.image.load_img(gen_forged_list[gf_id][1], target_size=(img_height, img_width))\n","            \n","            first_img_array[2*i+1] = tf.keras.preprocessing.image.img_to_array(first_img)\n","            second_img_array[2*i+1] = tf.keras.preprocessing.image.img_to_array(second_img)\n","\n","            #Genuine genuine-forged pair will be a given a label of '0'\n","            batch_labels[2*i+1] = 0\n","        \n","        #Normalize data\n","        first_img_array = tf.keras.applications.mobilenet.preprocess_input(first_img_array)\n","        second_img_array = tf.keras.applications.mobilenet.preprocess_input(second_img_array)\n","\n","        yield [first_img_array, second_img_array], batch_labels"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"KflfrwaObbTX"},"source":["#Check batch generator\n","a = batch_generator(train_g_g_pairs, train_g_f_pairs)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Q7smkiwsfqNV"},"source":["a"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"qpuYBFRjbivU"},"source":["X, y = next(a)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"7d5E3rLdK70g"},"source":["X[0].shape"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"jTgbj2tWK76P"},"source":["X[1].shape"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"tFwFZWkQfDmw"},"source":["y.shape"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"7PwSIIrlHkcG"},"source":["y"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"EkMXRqyZfSto"},"source":["#### Build Model"]},{"cell_type":"markdown","metadata":{"id":"pix5JrrrgKgF"},"source":["Load a pre-trained model (we can build a model from scratch as well)"]},{"cell_type":"code","metadata":{"id":"vql7Dga6fT_7"},"source":["mobilenet = tf.keras.applications.mobilenet.MobileNet(include_top=False, \n","                                                      input_shape=(img_height, img_width,3),\n","                                                      alpha=0.25,\n","                                                      weights='imagenet')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"jN94jN-5fuCz"},"source":["mobilenet.summary()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"63HBcG2vuGJZ"},"source":["#Number of layers in Mobilenet\n","len(mobilenet.layers)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"B_1PqDcruNGp"},"source":["#Lets' freeze all but last 15 layers\n","for layer in mobilenet.layers[:72]:\n","    layer.trainable=False"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"J4wu1qFyukWR"},"source":["mobilenet.summary()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"XSccHAlwgVB4"},"source":["Build a Siamese Network using Mobilenet as feature generator"]},{"cell_type":"code","metadata":{"id":"mP7OWcFTgbl1"},"source":["#Create two input layers - first and second image\n","first_input = tf.keras.layers.Input(shape=(img_height, img_width,3))\n","second_input = tf.keras.layers.Input(shape=(img_height, img_width,3))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"In0CjAhe2r26"},"source":["first_input"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"YbQV39ES2v5a"},"source":["second_input"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"qexPPs_Ugrrd"},"source":["#Generate features for first and second image\n","first_img_features = mobilenet(first_input)\n","second_img_features = mobilenet(second_input)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"e952as6rgr4A"},"source":["#Size of the outputs\n","first_img_features"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"p3SvZTmz21EW"},"source":["second_img_features"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"1_gjhK_Qjqmc"},"source":["#Lets flatten the features using Average pooling\n","gap_layer = tf.keras.layers.GlobalAveragePooling2D()\n","\n","#First img features\n","first_img_features = gap_layer(first_img_features)\n","#Second image features\n","second_img_features = gap_layer(second_img_features)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"o_XtMvU0kGky"},"source":["first_img_features"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"8yIBz-R5hjpR"},"source":["second_img_features"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"pFIcFINMkLu-"},"source":["We want to calculate Euclidean distance between two feature set. As there is no pre-built Euclidean distance layer in Keras, we will build one."]},{"cell_type":"code","metadata":{"id":"T8yA71drkGvK"},"source":["def euclidean_distance(features):\n","    \n","    #Get features\n","    x, y = features\n","\n","    #Calculate distance\n","    distance = tf.keras.backend.sqrt(tf.keras.backend.sum(tf.keras.backend.square(x - y), axis=1, keepdims=True))\n","    \n","    return distance"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Poz-43lWk-3R"},"source":["We will also need a function to define output shape of Euclidean distance layer"]},{"cell_type":"code","metadata":{"id":"wG1XWOH5k40X"},"source":["def eucl_dist_output_shape(shapes):\n","\n","    #Shapes of feature 1 and 2\n","    shape1, shape2 = shapes\n","    \n","    #Returned shape is equal to number of examples, 1\n","    return (shape1[0], 1)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Rn5HLsZ-lHP7"},"source":["Use Eucledean distance layer on features"]},{"cell_type":"code","metadata":{"id":"YIOuH3m5lMrM"},"source":["distance = tf.keras.layers.Lambda(euclidean_distance, \n","                                  output_shape=eucl_dist_output_shape)([first_img_features, second_img_features])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"MmmrQPXZikh9"},"source":["distance"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"zT6-P307l5Dc"},"source":["Build model"]},{"cell_type":"code","metadata":{"id":"5-779UAgl3-N"},"source":["model = tf.keras.Model([first_input, second_input], distance)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"mL1CvCg3ith_"},"source":["model.summary()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"2GQD86eEmHkm"},"source":["How do we calculate loss for Siamese network?"]},{"cell_type":"code","metadata":{"id":"YZogiZ3UnWFf"},"source":["def contrastive_loss(y_true, y_pred):\n","\n","    \"\"\"\n","    y_pred : Eucledean distance for each pair of images\n","    y_true : 1 for Genuine-genuine pair, 0 otherwise\n","    \n","    Contrastive loss from Hadsell-et-al.'06\n","    Source: http://yann.lecun.com/exdb/publis/pdf/hadsell-chopra-lecun-06.pdf\n","    \n","    Explanation:\n","    When ytrue is 1, that means the sample are duplicates of each other, \n","    so the Euclidean distance (ypred) between their outputs must be minimized.\n","    So the loss is taken as the square of that Euclidean distance itself - square(y_pred).\n","\n","    When ytrue is 0, i.e. the samples are not duplicates, then the Euclidean distance \n","    between them must be maximized, at least to the margin. So the loss to be minimized\n","    is the difference of the margin and the Euclidean distance - (margin - y_pred).\n","    If the Euclidean distance (ypred) is already greater than the margin, \n","    then nothing is to be learned, so the loss is made to be zero in \n","    that case by saying maximum(margin - y_pred, 0).\n","    \"\"\"\n","\n","    margin = 1\n","\n","    #Loss when pairs are genuine-genuine\n","    positive_loss = tf.keras.backend.square(y_pred)\n","    \n","    #Loss when pairs are genuine-fake\n","    negative_loss = tf.keras.backend.square(tf.keras.backend.maximum(margin - y_pred, 0))\n","\n","    #Total loss\n","    total_loss = y_true * positive_loss + (1 - y_true) * negative_loss\n","    \n","    #Calculate average loss\n","    total_average_loss = tf.keras.backend.mean(total_loss)\n","\n","    return total_average_loss"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"QoXmEpF2nlgS"},"source":["Compile the model with optimizer and loss"]},{"cell_type":"code","metadata":{"id":"UXA8T8ONnnzv"},"source":["model.compile(optimizer='adam', loss=contrastive_loss)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"w9BEs2VpnyEX"},"source":["model.summary()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"zctr-X7Sn2wv"},"source":["#### Train Model"]},{"cell_type":"code","metadata":{"id":"kkA103s-oMSh"},"source":["#Total training and test examples\n","total_train_examples = len(train_g_g_pairs) + len(train_g_f_pairs)\n","total_test_examples = len(test_g_g_pairs) + len(test_g_f_pairs)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"nNnPEhlpOqAR"},"source":["total_train_examples, total_test_examples"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"pnLvtqe9n1Bv"},"source":["#Create Train and Test batch generators\n","batch_size = 128\n","train_generator = batch_generator(train_g_g_pairs, train_g_f_pairs, batch_size=batch_size)\n","test_generator = batch_generator(test_g_g_pairs, test_g_f_pairs, batch_size=batch_size)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"qxwqkUi8pG_f"},"source":["#Model checkpoint to save the best model\n","model_ckpt = tf.keras.callbacks.ModelCheckpoint('signature_siamese.h5', \n","                                                save_best_only=True, \n","                                                monitor='val_loss',\n","                                                verbose=1)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"jrV-3h8FoZ_k"},"source":["#Start training\n","model.fit(train_generator,\n","          epochs=1,\n","          steps_per_epoch=total_train_examples//batch_size, \n","          validation_data=test_generator, \n","          validation_steps=total_test_examples//batch_size, \n","          callbacks=[model_ckpt])"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"4xXYjsMUAy7y"},"source":["#### Save Model"]},{"cell_type":"code","metadata":{"id":"UsJ5o5gvAfzL"},"source":["#Connect to Google drive\n","from google.colab import drive\n","drive.mount('/gdrive')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Bm4dSAOs_8iS"},"source":["#Save model - change path to whatever you want\n","save_path = '/gdrive/My Drive/Great Learning/ACV - II/Notebooks/3. Siamese Network/Signature_siamese.h5'\n","#model.save(save_path)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"keMTaG-lA3M0"},"source":["#Load model\n","model = tf.keras.models.load_model(save_path, custom_objects={'contrastive_loss':contrastive_loss})"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"fxsbC7iJBwEJ"},"source":["#Make sure model has loaded\n","model.summary()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"X28jYq8NqkmF"},"source":["#### Model Accuracy"]},{"cell_type":"markdown","metadata":{"id":"QTlVj7zp7o02"},"source":["Calculate prediction for all test examples"]},{"cell_type":"code","metadata":{"id":"aYh7abc2vcuD"},"source":["#Build predictions\n","predictions = []\n","true_labels = []"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"3ho03lUb8q5S"},"source":["for i in tqdm(range(total_test_examples//batch_size)):\n","\n","    #Get batch\n","    X, y = next(test_generator)\n","    #Model predictions\n","    distances = model.predict(X)\n","\n","    #Capture it in the labels and predictions list\n","    for j in range(y.shape[0]):\n","        true_labels.append(int(y[j][0]))\n","        predictions.append(distances[j][0])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"VaSN7S47-K0B"},"source":["len(predictions), len(true_labels)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"E9a9xd1fLjrM"},"source":["predictions[:10]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"JVlOvLLUNgyC"},"source":["true_labels[:10]"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"DPH3Dx2NqnpV"},"source":["How do we calculate a **threshold** above which images will be considered as genuine-forged pair?\n","\n","*We can check at which distance, test accuracy is highest and consider that as a threhold.*"]},{"cell_type":"code","metadata":{"id":"CZPIyYydqnCO"},"source":["def compute_accuracy_thresh(predictions, labels):\n","    \n","    \"\"\"\n","    Compute accuracy with a range of thresholds on distances.\n","    \"\"\"\n","\n","    #Get maximum and minimum value of distance for test examples\n","    dmax = np.max(predictions)\n","    dmin = np.min(predictions)\n","    print(dmin, dmax)\n","\n","    #How many pairs are genuine-genuine and how many are genuine-forged in test data\n","    n_gg_pairs = np.sum(labels == 1)\n","    n_gf_pairs = np.sum(labels == 0)\n","    \n","    #We will increment threhold by\n","    step = 0.01\n","\n","    #Initialize Accuracy and threshold\n","    max_acc = 0\n","    best_thresh = -1\n","\n","    #Run through a look increasing threshold by step amount and checking accuracy   \n","    for d in np.arange(dmin, dmax+step, step):\n","\n","        #Test examples for which predicted distance was less than or equal to d (threshold)\n","        #These can be taken as genuine-genuine pairs (for given threshold)\n","        idx1 = predictions.ravel() <= d\n","        \n","        #Test examples for which predicted distance > d (genuine-forged pairs)\n","        idx2 = predictions.ravel() > d\n","       \n","        #How many positive examples are correct\n","        true_positive_rate = float(np.sum(labels[idx1] == 1)) / n_gg_pairs   \n","        true_negative_rate = float(np.sum(labels[idx2] == 0)) / n_gf_pairs\n","        \n","        #Accuracy - avg of above two terms\n","        acc = (true_positive_rate + true_negative_rate)/2       \n","\n","        #If accuracy improved from previous best, make a note of it\n","        #print('Previous Accuracy, Best threshold', max_acc, best_thresh)\n","        #print('Current Accuracy and Threshold', acc, d)    \n","        if (acc > max_acc):\n","            max_acc, best_thresh = acc, d\n","           \n","    return max_acc, best_thresh"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"XQSVNodYwaEB"},"source":["Calculate best threshold and accuracy"]},{"cell_type":"code","metadata":{"id":"H61woxSCuxKi"},"source":["test_acc, threshold = compute_accuracy_thresh(np.array(predictions), np.array(true_labels))\n","print('Test accuracy:', round(test_acc,2))\n","print('Best distance threshold:', round(threshold,2))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"_4c__eXSxXNW"},"source":["#### Visualize Model Prediction"]},{"cell_type":"markdown","metadata":{"id":"M9JFtZau8602"},"source":["During Training:\n","\n","1. Load Image\n","2. Resize Image\n","3. Convert it into Numpy array\n","4. Image Augmentation\n","        - Rotate, Scale, shear, flip, add Noise, Translate etc\n","5. (Transfer Learning) - Normalize your image array\n","\n","During Prediction:\n","\n","1. Load Image\n","2. Resize Image\n","3. Convert it into Numpy array\n","4. (Transfer Learning) - Normalize your image array"]},{"cell_type":"code","metadata":{"id":"z1bRPdtlxaw7"},"source":["def visualize_prediction(img_pairs, label):\n","\n","    #Load images\n","    first_img = tf.keras.preprocessing.image.load_img(img_pairs[0], target_size=(img_height, img_width))\n","    second_img = tf.keras.preprocessing.image.load_img(img_pairs[1], target_size=(img_height, img_width))\n","    \n","    #Convert to array\n","    first_img_array = tf.keras.preprocessing.image.img_to_array(first_img)\n","    second_img_array = tf.keras.preprocessing.image.img_to_array(second_img)\n","\n","    #Convert to a batch\n","    first_img_array = np.expand_dims(first_img_array, axis=0)\n","    second_img_array = np.expand_dims(second_img_array, axis=0)\n","\n","    #Normalize data\n","    first_img_array_norm = tf.keras.applications.mobilenet.preprocess_input(first_img_array)\n","    second_img_array_norm = tf.keras.applications.mobilenet.preprocess_input(second_img_array)\n","\n","    #Model prediction - distance\n","    distance = model.predict([first_img_array_norm, second_img_array_norm])\n","    print(distance)\n","\n","    print('Actual label:', label)\n","\n","    if distance <= threshold:\n","        print('Predicted label:', 'Genuine-Genuine')\n","    else:\n","        print('Predicted label:', 'Genuine-Fake')\n","    \n","    fig, (ax1, ax2) = plt.subplots(1, 2, figsize = (10, 10))\n","    ax1.imshow(plt.imread(img_pairs[0]), cmap='gray')\n","    ax2.imshow(plt.imread(img_pairs[1]), cmap='gray')\n","    plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"cHGCy1EEnWF8"},"source":["#Visualize for genuine-genuine pair\n","idx = np.random.randint(0, len(test_g_g_pairs))\n","visualize_prediction(test_g_g_pairs[idx], 'Genuine-Genuine')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"cXWBvimJ0ZmM"},"source":["#Visualize for genuine-forged pair\n","idx = np.random.randint(0, len(test_g_f_pairs))\n","visualize_prediction(test_g_f_pairs[idx], 'Genuine-Fake')"],"execution_count":null,"outputs":[]}]}